{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a16733-a437-442e-832c-5d29e73d723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ccce99-a9c4-4bc5-9251-61dfd7ba53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b49126d-9bea-4b75-b6ba-93dace6c8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb70599d-90de-4774-b33f-b52418dc3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.zoetis.com/'\n",
    "job_description=\"\"\"    Kalamazoo - Downtown Portage Street\n",
    "\n",
    "time type\n",
    "    Full time\n",
    "\n",
    "posted on\n",
    "    Posted 30+ Days Ago\n",
    "\n",
    "job requisition id\n",
    "    JR00016811\n",
    "\n",
    "States considered: All\n",
    "\n",
    "Role Description:\n",
    "\n",
    "precision animal HEALTH GENERATIVE AI Internship\n",
    "\n",
    "Location: Remote but based in Kalamazoo, MI\n",
    "\n",
    "Internship Summary:\n",
    "\n",
    "The ideal candidate will apply machine learning, deep learning, and generative AI approaches to support the development of advanced technologies for use in farm settings. This role will emphasize integrating natural language processing and chatbot functionality to improve the accessibility and usability of data insights for end users. The internship will also involve building end-to-end solutions that link front-end interfaces with back-end data systems. \n",
    "\n",
    "Internship Job Duties:\n",
    "\n",
    "    Gain familiarity with Zoetis Precision Animal Health data collection and recording systems, with a focus on integrating chatbot and NLP technologies.\n",
    "    Contribute to research and development efforts in machine learning, deep learning, and generative AI for product enhancement.\n",
    "    Develop and deploy NLP models to support natural language understanding and generation, enabling improved interactions through chatbots and other interfaces.\n",
    "    Collaborate on building front-end and back-end connectivity to ensure smooth data flow and user interface integration.\n",
    "    Analyze and manage disparate data sources, and clearly communicate technical results and methods.\n",
    "    Interact cross-functionally with internal and external teams to align technical solutions with user needs.\n",
    "\n",
    "Internship Qualifications:\n",
    "\n",
    "Education:\n",
    "\n",
    "    Currently enrolled in a graduate degree program in a quantitative or technical discipline (e.g., computer science, data science, engineering, statistics, statistical genetics, industrial engineering, computational biology, applied mathematics, applied physics, or similar).\n",
    "\n",
    "Technical Skills:\n",
    "\n",
    "    Experience developing, training, and deploying machine learning and deep learning models using public libraries (e.g., TensorFlow, Keras, Sklearn, PyTorch) in Python.\n",
    "    Familiarity with natural language processing (NLP) techniques and models, particularly for applications in chatbot and language generation technologies (e.g., Transformer-based models like BERT, GPT).\n",
    "    Knowledge of generative AI approaches and experience in implementing and fine-tuning generative models (GANs, VAEs, etc.) is a plus.\n",
    "    Proficiency in using APIs for model deployment, including working with tools like the OpenAI GPT API or similar frameworks for integrating NLP capabilities into applications.\n",
    "    Proficiency in front-end and back-end integration, with a working understanding of connecting models with user interfaces and databases to enable end-to-end solutions.\n",
    "\n",
    "General Skills:\n",
    "\n",
    "A background in animal agriculture is desired but not essential.\n",
    "\n",
    "Ability to work independently and collaboratively as part of a team.\n",
    "\n",
    "    Strong communication skills, including the ability to present complex technical methods and results clearly to non-technical audiences.\n",
    "    Demonstrated problem-solving, analytical, and organizational skills.\n",
    "\n",
    "Additional Requirements:\n",
    "\n",
    "    At least 18 years of age and authorized to work in the U.S.\n",
    "    Must be enrolled in a degree program during the Spring term preceding the internship.\n",
    "\n",
    "Successfully pass a background check and drug screen.\n",
    "\n",
    "The following hourly pay rates reflect the anticipated base pay for this position:\n",
    "\n",
    " \n",
    "\n",
    "If the selected candidate is a student pursuing an Associate-level degree: $16.00 per hour\n",
    "\n",
    "If the selected candidate is a student pursuing an Undergraduate-level degree: $20.00 per hour \n",
    "\n",
    "If the selected candidate is a student pursing a Graduate-level degree: $32.50 per hour \n",
    "\n",
    "If the selected candidate is a student pursuing a Doctorate-level degree: $36.00 per hour\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "The following hourly pay rates reflect the anticipated base pay for this position if a selected candidate were to be located in California, Connecticut, District of Columbia, Illinois (Chicago area), Massachusetts, New Jersey, New York, Washington (Seattle area):\n",
    "\n",
    " \n",
    "\n",
    "Student pursuing an Associate-level degree: $17.00 per hour\n",
    "\n",
    "Student pursuing an Undergraduate-level degree: $22.00 per hour \n",
    "\n",
    "Student pursing a Graduate-level degree: $36.40 per hour \n",
    "\n",
    "Student pursuing a Doctorate-level degree: $40.30 per hour\n",
    "\n",
    "Full time\n",
    "\n",
    "Intern (Trainee)\n",
    "\n",
    "Colleague\n",
    "\n",
    "Any unsolicited resumes sent to Zoetis from a third party, such as an Agency recruiter, including unsolicited resumes sent to a Zoetis mailing address, fax machine or email address, directly to Zoetis employees, or to Zoetis resume database will be considered Zoetis property. Zoetis will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n",
    "\n",
    "Zoetis will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred by the Agency free of any charges or fees. This includes any Agency that is an approved/engaged vendor but does not have the appropriate approvals to be engaged on a search.\n",
    "\n",
    "Zoetis is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status or any other protected classification. Disabled individuals are given an equal opportunity to use our online application system. We offer reasonable accommodations as an alternative if requested by an individual with a disability. Please contact Zoetis Colleague Services at zoetiscolleagueservices@zoetis.com to request an accommodation. Zoetis also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must possess or obtain authorization to work in the US for Zoetis. Zoetis retains sole and exclusive discretion to pursue sponsorship for the acquisition or maintenance of nonimmigrant status and employment eligibility, considering factors such as availability of qualified US workers. Individuals requiring sponsorship must disclose this fact. Please note that Zoetis seeks information related to job applications from candidates for jobs in the U.S. solely via the following:  (1) our company website at www.Zoetis.com/careers site, or (2) via email to/from addresses using only the Zoetis domain of “@zoetis.com”. In addition, Zoetis does not use Google Hangout for any recruitment related activities.  Any solicitation or request for information related to job applications with Zoetis via any other means and/or utilizing email addresses with any other domain should be disregarded.  In addition, Zoetis will never ask candidates to make any type of personal financial investment related to gaining employment with Zoetis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6061e5de-266f-44b3-a943-cc5c95e1d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SummarizationAgent:\n",
    "    def __init__(self):\n",
    "        self.link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "        You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "        such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "        \n",
    "        self.link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "        self.link_system_prompt += \"\"\"\n",
    "        {\n",
    "            \"links\": [\n",
    "                {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "                {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "            ]\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        self.link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "        Your task is to determine which links are most relevant for finding job-related information, \\\n",
    "        including job postings, team structures, related projects, departments, company research, and company news. \\\n",
    "        Prioritize pages that provide context about the job role and its industry impact.\\n\"\n",
    "        self.link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "        self.link_system_prompt += \"\"\"\n",
    "                {\n",
    "                    \"links\": [\n",
    "                        {\"type\": \"job posting\", \"url\": \"https://full.url/goes/here/job-title\"},\n",
    "                        {\"type\": \"careers page\", \"url\": \"https://full.url/goes/here/careers\"},\n",
    "                        {\"type\": \"team/department page\", \"url\": \"https://full.url/goes/here/team\"},\n",
    "                        {\"type\": \"project/research page\", \"url\": \"https://full.url/goes/here/project\"},\n",
    "                        {\"type\": \"company news\", \"url\": \"https://full.url/goes/here/news\"}\n",
    "                    ]\n",
    "                }\n",
    "        \"\"\"\n",
    "\n",
    "        self.system_prompt = \"You are an assistant that searches for and extracts all available information related to a job posting from a company website. \\\n",
    "                Your goal is to gather as much detail as possible to help the user understand the job role, its responsibilities, \\\n",
    "                the projects it is related to, the team or department it belongs to, and any background about the company’s work in this area. Find anything that can be related to keywords in job description\\\n",
    "                Analyze relevant webpages, including careers, company projects, teams, and news, to provide a comprehensive understanding \\\n",
    "                of the job in its full context. Preserve all relevant text and descriptions while ensuring clarity and completeness. \\\n",
    "                Respond in Markdown format.\"\n",
    "\n",
    "        load_dotenv(override=True)\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "        self.MODEL = 'gpt-4o-mini'\n",
    "        self.openai = OpenAI()\n",
    "        \n",
    "\n",
    "    \n",
    "    def generate_search_term(self, job_description):\n",
    "        \"\"\"Use OpenAI to generate an optimized search term based on the job description.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Given the following job description, generate the best search term to find relevant information about this role, \n",
    "        including company projects, industry focus, and related news. The search term should be concise and effective for Google search.\n",
    "    \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "    \n",
    "        Provide only the search term without explanation.\n",
    "        \"\"\"\n",
    "    \n",
    "        try:\n",
    "            response=self.openai.chat.completions.create(\n",
    "                model=self.MODEL,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are an expert at creating effective Google search queries.\"},\n",
    "                              {\"role\": \"user\", \"content\": prompt}],\n",
    "            )\n",
    "            # response = openai.chat.completions.create(\n",
    "            #     model=MODEL,\n",
    "            #     messages=[{\"role\": \"system\", \"content\": \"You are an expert at creating effective Google search queries.\"},\n",
    "            #               {\"role\": \"user\", \"content\": prompt}],\n",
    "            #     # max_tokens=20\n",
    "            # )\n",
    "            return response.choices[0].message.content \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating search term: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def google_search(self, search_query, num_results=20):\n",
    "        \"\"\"Perform a Google search and get the first `num_results` relevant links (Free method).\"\"\"\n",
    "        links = []\n",
    "        try:\n",
    "            \n",
    "            for url in search(search_query, num_results=num_results):#, stop=num_results, pause=2):\n",
    "                links.append(url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Google search: {e}\")\n",
    "        \n",
    "        return links\n",
    "        \n",
    "    def get_links_user_prompt(self, website, job_description):\n",
    "        user_prompt = f\"Here is a job description for a position at {website.url}:\\n\\n{job_description}\\n\\n\"\n",
    "        user_prompt += \"Please determine which pages on the company website are relevant to this job and its context, including job details (job responsibilities, Required Qualifications, preferred requirements, job title), \\\n",
    "                        related projects, teams, departments, research, and company news. Identify all relevant web links and return the full \\\n",
    "                        https URLs in JSON format. Do not include Terms of Service, Privacy Policy, email links, or unrelated pages.\\n\"\n",
    "        user_prompt += \"Links (some might be relative links):\\n\"\n",
    "        user_prompt += \"\\n\".join(website.links)\n",
    "\n",
    "\n",
    "        \n",
    "        # user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "        # user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "        #                 Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "        # user_prompt += \"Links (some might be relative links):\\n\"\n",
    "        # user_prompt += \"\\n\".join(website.links)\n",
    "        return user_prompt\n",
    "\n",
    "\n",
    "    def get_links(self, url, job_desc):\n",
    "        website = Website(url)\n",
    "        # completion: your task is completing this conversation\n",
    "        response = self.openai.chat.completions.create(\n",
    "            model=self.MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.get_links_user_prompt(website, job_desc)}\n",
    "          ],\n",
    "            response_format={\"type\": \"json_object\"} # we tell OpenAI, we want Json object back in its response. OpenAI in its documentation recommend that it's still important that you mention in your prompt that a json response is required even if you specify format in this argument.\n",
    "        )\n",
    "        result = response.choices[0].message.content \n",
    "        # dot choices zero. So what's this about? Well, as it happens we can actually in the API request ask to have multiple variations if we want, \n",
    "        # if we wanted it to generate several possible variations of the response. And we haven't done that. So we're only going to get back one.\n",
    "        # Uh, and so those variations come back in the form of these choices. But we've only got one. So choices zero is getting us the one and the only choice of the response back.\n",
    "        return json.loads(result)  # we use json.loads to bring it back as JSON.\n",
    "\n",
    "\n",
    "    # get content of page and link. Go into links and collect content\n",
    "    # def get_all_details(self, url):\n",
    "    #     result = \"Landing page:\\n\"\n",
    "    #     result += Website(url).get_contents()\n",
    "    #     links = self.get_links(url)\n",
    "    #     print(\"Found links:\", links)\n",
    "    #     for link in links[\"links\"]:\n",
    "    #         result += f\"\\n\\n{link['type']}\\n\"\n",
    "    #         result += Website(link[\"url\"]).get_contents()\n",
    "    #     return result\n",
    "\n",
    "    \n",
    "    def get_all_details(self, url, job_desc, company_name, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "    \n",
    "        # Avoid revisiting the same page\n",
    "        if url in visited:\n",
    "            return \"\"\n",
    "    \n",
    "        visited.add(url)\n",
    "    \n",
    "        result = f\"Page: {url}\\n\"\n",
    "        result += Website(url).get_contents()\n",
    "    \n",
    "        # Get all links from the current page\n",
    "        links = self.get_links(url, job_desc)\n",
    "    \n",
    "        for link in links.get(\"links\", []):\n",
    "            link_url = link[\"url\"]\n",
    "    \n",
    "            # Ensure the link belongs to the same company domain\n",
    "            if self.is_same_domain(url, link_url):  \n",
    "                result += f\"\\n\\n{link['type']}\\n\"\n",
    "                result += self.get_all_details(link_url, job_desc, visited)  # Recursive call\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def is_same_domain(self, base_url, target_url):\n",
    "        \"\"\"Helper function to check if the target_url is within the same company domain.\"\"\"\n",
    "        base_domain = urlparse(base_url).netloc\n",
    "        target_domain = urlparse(target_url).netloc\n",
    "        return base_domain == target_domain\n",
    "        \n",
    "    \n",
    "\n",
    "    def get_brochure_user_prompt(self,company_name, job_desc, url):\n",
    "        # user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "        # user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "        # user_prompt += self.get_all_details(url)\n",
    "        user_prompt = f\"You are researching a company called: {company_name}.\\n\\n\"\n",
    "        user_prompt += \"Below are the contents of its landing page and other relevant pages. Your goal is to extract and analyze \\\n",
    "                        all information related to a specific job position to help the user understand its full context within the company.\\n\\n\"\n",
    "        \n",
    "        user_prompt += \"### **Instructions:**\\n\"\n",
    "        user_prompt += \"- Identify and extract all details about the job, including responsibilities, qualifications, and benefits.\\n\"\n",
    "        user_prompt += \"- Find information on the department, team, or projects this job is associated with.\\n\"\n",
    "        user_prompt += \"- Look for company initiatives, research, or ongoing work that may relate to this role.\\n\"\n",
    "        user_prompt += \"- Extract any relevant company culture, values, or work environment details that impact this position.\\n\"\n",
    "        user_prompt += \"- If available, include company news, innovations, or industry focus related to the job role.\\n\"\n",
    "        user_prompt += \"- Provide a structured and comprehensive response in Markdown format for clarity.\\n\"\n",
    "        user_prompt += \"- Only show the connections in job descriptions and the webpage content to see what are related things\\n\"\n",
    "        user_prompt += \"- focus on everything that is related to the job description especially the job title/position title\\n\"\n",
    "        user_prompt += \"- if you do not find the related content, just output no information found. Do not generate unnecessary info\\n\"\n",
    "        user_prompt += \"\\n### **Job & Company Information:**\\n\"\n",
    "        user_prompt += self.get_all_details(url, job_desc, company_name)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # Google Search\n",
    "        search_term = self.generate_search_term(job_description)\n",
    "        search_query = f\"{search_term} {company_name}\"  # Append company name to the search term\n",
    "    \n",
    "        print(f\"Searching Google for: {search_query}\")\n",
    "        links = google_search(search_query)\n",
    "        for link in links:\n",
    "            user_prompt += self.get_all_details(link, job_desc, company_name)\n",
    "\n",
    "        # Google Search\n",
    "        search_term = self.generate_search_term(job_description)\n",
    "        search_query = f\"{search_term} {company_name}\"  # Append company name to the search term\n",
    "    \n",
    "        print(f\"Searching Google for: {search_query}\")\n",
    "        links = google_search(search_query)\n",
    "        print(\"Found links:\", links)\n",
    "\n",
    "        user_prompt = user_prompt[:10_000] # Truncate if more than 10,000 characters, just in case\n",
    "        return user_prompt\n",
    "\n",
    "\n",
    "    def create_brochure(self, company_name, url, job_desc):\n",
    "        response = self.openai.chat.completions.create(\n",
    "            model=self.MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.get_brochure_user_prompt(company_name, job_desc, url)}\n",
    "              ],\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9290671a-c51c-49f9-a21d-3272f802f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_3489/1336606372.py\u001b[0m(155)\u001b[0;36mget_all_details\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    153 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    154 \u001b[0;31m        \u001b[0;31m# Google Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 155 \u001b[0;31m        \u001b[0msearch_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_search_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    156 \u001b[0;31m        \u001b[0msearch_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{search_term} {company_name}\"\u001b[0m  \u001b[0;31m# Append company name to the search term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    157 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  links\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'links': [{'type': 'job posting', 'url': 'https://careers.zoetis.com/'}, {'type': 'internship page', 'url': 'https://careers.zoetis.com/join-us/intern-at-zoetis'}, {'type': 'careers page', 'url': 'https://careers.zoetis.com/join-us/careers-at-zoetis'}, {'type': 'research/project page', 'url': 'https://www.zoetis.com/products-and-science/research-development'}, {'type': 'company news', 'url': 'https://news.zoetis.com/news-insights'}]}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "# SA=SummarizationAgent()\n",
    "# SA.create_brochure(\"HuggingFace\", \"https://huggingface.com\") \n",
    "\n",
    "SA=SummarizationAgent()\n",
    "SA.create_brochure('Zoetis',url, job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9e9832-6578-42d6-bbdf-a91dcd33ff89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_description' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjob_description\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'job_description' is not defined"
     ]
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba153cc-7428-4e06-a17d-2e8dbf338c51",
   "metadata": {},
   "source": [
    "# Next implementation\n",
    "I used this implementation, but I found that the job description does not exist in the company website. \n",
    "\n",
    "This is the description of this implementation:\n",
    "\n",
    "`I want to write a code that collect all the information from webpages of a website, summarize each page in one paragraph,  and returns the related information to the job description. The web pages whose summary are related to the job description should be returned in a json format. This pages finallly, will be used to provide output for the user, as information on the company's website related to the job description. I do not want to do all of them together. Do these step by step. First, collecting web pages information, collecting summary of each page via openai-mini. second, use openai-mini to find the related pages based on collected summaries. third, returning the related pages' links. fourth, reading the content of links and create a markdown format of all information related to the job description. It can be summary or structured format that shows everything with a reference link in a table format or bullet point format`\n",
    "\n",
    "This implementation is not useful. It can not find anything on companies website, however, it is a deeper search. On the other side, it looks like the summary of pages does not help in finding the related information to the job description. So, the google search is more promising in this case because google does the job for us to find the related pages. The next implementation does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "065f20a7-f2a8-4b8a-aa57-b5ed8001a0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://www.zoetis.com/\n",
      "Fetching: https://www.zoetis.com/join-us/diversity-equity-inclusion\n",
      "Fetching: https://www.zoetis.com/our-company/our-locations\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/solensia\n",
      "Fetching: https://www.zoetis.com/products-and-science/manufacturing-supply\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/revolution-plus\n",
      "Fetching: https://www.zoetis.com/#site-header-search\n",
      "Fetching: https://www.zoetis.com/our-company/our-story/about-us\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971541\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/simparica-trio\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971533\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/apoquel\n",
      "Fetching: https://www.zoetis.com/products-and-science/compound-transfer-program\n",
      "Fetching: https://www.zoetis.com/our-company/corporate-sustainability/advancing-sustainability-in-animal-health-for-a-better-future\n",
      "Fetching: https://www.zoetis.com/news-and-insights/innovators-for-animals\n",
      "Fetching: https://www.zoetis.com/our-company/our-story/board-of-directors/\n",
      "Fetching: https://www.zoetis.com/customer-care#get-in-touch\n",
      "Fetching: https://www.zoetis.com/products-and-science/equine\n",
      "Fetching: https://www.zoetis.com/products-and-science/livestock\n",
      "Fetching: https://www.zoetis.com/suppliers\n",
      "Fetching: https://www.zoetis.com/products-and-science/diagnostics\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971531\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971534\n",
      "Fetching: https://www.zoetis.com/news-and-insights/news-insights\n",
      "Fetching: https://www.zoetis.com/our-company/our-story/executive-team/\n",
      "Fetching: https://www.zoetis.com/our-company/awards-and-recognition/recent-awards-recognition\n",
      "Fetching: https://www.zoetis.com/products-and-science/petcare\n",
      "Fetching: https://www.zoetis.com/our-company/zoetis-foundation/\n",
      "Fetching: https://www.zoetis.com/customer-care/\n",
      "Fetching: https://www.zoetis.com/join-us/life-at-zoetis\n",
      "Fetching: https://www.zoetis.com/our-company/corporate-governance\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971539\n",
      "Fetching: https://www.zoetis.com/terms-of-use\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/librela\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971540\n",
      "Fetching: https://www.zoetis.com/join-us/\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/draxxin-kp\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/cytopoint\n",
      "Fetching: https://www.zoetis.com/news-and-insights/blog/transforming-drug-discovery-and-development-with-generative-ai\n",
      "Fetching: https://www.zoetis.com/news-and-insights/feature-story-archive\n",
      "Fetching: https://www.zoetis.com/contact-us\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971538\n",
      "Fetching: https://www.zoetis.com/#headernavsiteselector\n",
      "Fetching: https://www.zoetis.com/join-us/careers-at-zoetis\n",
      "Fetching: https://www.zoetis.com/privacy-center\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971536\n",
      "Fetching: https://www.zoetis.com/news-and-insights/media-kit\n",
      "Fetching: https://www.zoetis.com/products-and-science/products/all-products?type=971535\n",
      "Fetching: https://www.zoetis.com/our-company/cmo\n",
      "Fetching: https://www.zoetis.com/news-and-insights/on-purpose/on-purpose-with-kristin-peck\n",
      "Fetching: https://www.zoetis.com/products-and-science/research-development\n",
      "Fetching: https://www.zoetis.com/#page\n",
      "Fetching: https://www.zoetis.com/products-and-science/partnering-with-zoetis\n",
      "Fetching: https://www.zoetis.com/our-company/corporate-compliance\n",
      "Fetching: https://www.zoetis.com/join-us/intern-at-zoetis\n",
      "Webpage collection complete!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self):\n",
    "        self.visited = set()\n",
    "        self.pages = {}\n",
    "\n",
    "    def is_same_domain(self, base_url, target_url):\n",
    "        \"\"\"Check if the target URL belongs to the same domain as base_url.\"\"\"\n",
    "        base_domain = urlparse(base_url).netloc\n",
    "        target_domain = urlparse(target_url).netloc\n",
    "        return base_domain == target_domain\n",
    "\n",
    "    def get_links(self, url):\n",
    "        \"\"\"Extract all internal links from a webpage.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            links = set()\n",
    "\n",
    "            for a_tag in soup.find_all(\"a\", href=True):\n",
    "                link = a_tag[\"href\"]\n",
    "                full_url = requests.compat.urljoin(url, link)\n",
    "                \n",
    "                if self.is_same_domain(url, full_url):\n",
    "                    links.add(full_url)\n",
    "\n",
    "            return list(links)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching links from {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_page_content(self, url):\n",
    "        \"\"\"Extract visible text content from a webpage.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()\n",
    "\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            return text[:5000]  # Limit content length to avoid too much data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching content from {url}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def crawl_website(self, url, depth=2):\n",
    "        \"\"\"Recursively crawl the website, collecting content from all pages.\"\"\"\n",
    "        if url in self.visited or depth == 0:\n",
    "            return\n",
    "\n",
    "        print(f\"Fetching: {url}\")\n",
    "        self.visited.add(url)\n",
    "        page_content = self.get_page_content(url)\n",
    "        if page_content:\n",
    "            self.pages[url] = page_content\n",
    "\n",
    "        links = self.get_links(url)\n",
    "        time.sleep(1)  # Delay to avoid overloading the server\n",
    "\n",
    "        for link in links:\n",
    "            self.crawl_website(link, depth - 1)\n",
    "\n",
    "        return self.pages  # Return dictionary of {url: content}\n",
    "\n",
    "\n",
    "# Usage\n",
    "scraper = WebScraper()\n",
    "company_website = \"https://www.zoetis.com/\"  # Replace with actual company website\n",
    "collected_pages = scraper.crawl_website(company_website)\n",
    "\n",
    "# Save collected pages for next steps\n",
    "import json\n",
    "with open(\"collected_pages.json\", \"w\") as f:\n",
    "    json.dump(collected_pages, f, indent=4)\n",
    "\n",
    "print(\"Webpage collection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf05ec5-6c37-44db-b211-2ab956b2255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing: https://www.zoetis.com/\n",
      "Summarizing: https://www.zoetis.com/join-us/diversity-equity-inclusion\n",
      "Summarizing: https://www.zoetis.com/our-company/our-locations\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/solensia\n",
      "Summarizing: https://www.zoetis.com/products-and-science/manufacturing-supply\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/revolution-plus\n",
      "Summarizing: https://www.zoetis.com/#site-header-search\n",
      "Summarizing: https://www.zoetis.com/our-company/our-story/about-us\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971541\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/simparica-trio\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971533\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/apoquel\n",
      "Summarizing: https://www.zoetis.com/products-and-science/compound-transfer-program\n",
      "Summarizing: https://www.zoetis.com/our-company/corporate-sustainability/advancing-sustainability-in-animal-health-for-a-better-future\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/innovators-for-animals\n",
      "Summarizing: https://www.zoetis.com/our-company/our-story/board-of-directors/\n",
      "Summarizing: https://www.zoetis.com/customer-care#get-in-touch\n",
      "Summarizing: https://www.zoetis.com/products-and-science/equine\n",
      "Summarizing: https://www.zoetis.com/products-and-science/livestock\n",
      "Summarizing: https://www.zoetis.com/suppliers\n",
      "Summarizing: https://www.zoetis.com/products-and-science/diagnostics\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971531\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971534\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/news-insights\n",
      "Summarizing: https://www.zoetis.com/our-company/our-story/executive-team/\n",
      "Summarizing: https://www.zoetis.com/our-company/awards-and-recognition/recent-awards-recognition\n",
      "Summarizing: https://www.zoetis.com/products-and-science/petcare\n",
      "Summarizing: https://www.zoetis.com/our-company/zoetis-foundation/\n",
      "Summarizing: https://www.zoetis.com/customer-care/\n",
      "Summarizing: https://www.zoetis.com/join-us/life-at-zoetis\n",
      "Summarizing: https://www.zoetis.com/our-company/corporate-governance\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971539\n",
      "Summarizing: https://www.zoetis.com/terms-of-use\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/librela\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971540\n",
      "Summarizing: https://www.zoetis.com/join-us/\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/draxxin-kp\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/cytopoint\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/blog/transforming-drug-discovery-and-development-with-generative-ai\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/feature-story-archive\n",
      "Summarizing: https://www.zoetis.com/contact-us\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971538\n",
      "Summarizing: https://www.zoetis.com/#headernavsiteselector\n",
      "Summarizing: https://www.zoetis.com/join-us/careers-at-zoetis\n",
      "Summarizing: https://www.zoetis.com/privacy-center\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971536\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/media-kit\n",
      "Summarizing: https://www.zoetis.com/products-and-science/products/all-products?type=971535\n",
      "Summarizing: https://www.zoetis.com/our-company/cmo\n",
      "Summarizing: https://www.zoetis.com/news-and-insights/on-purpose/on-purpose-with-kristin-peck\n",
      "Summarizing: https://www.zoetis.com/products-and-science/research-development\n",
      "Summarizing: https://www.zoetis.com/#page\n",
      "Summarizing: https://www.zoetis.com/products-and-science/partnering-with-zoetis\n",
      "Summarizing: https://www.zoetis.com/our-company/corporate-compliance\n",
      "Summarizing: https://www.zoetis.com/join-us/intern-at-zoetis\n",
      "Summarization complete!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "# Load collected web pages\n",
    "with open(\"collected_pages.json\", \"r\") as f:\n",
    "    collected_pages = json.load(f)\n",
    "\n",
    "# OpenAI API Configuration (Replace with your API key)\n",
    "# openai.api_key = \"your-api-key\"\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Use OpenAI-mini to summarize a webpage's content.\"\"\"\n",
    "    prompt = f\"Summarize the following webpage content in one concise paragraph:\\n\\n{text[:4000]}\"  # Truncate if too long\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert at summarizing website content.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "        # response_format={\"type\": \"json_object\"} # we tell OpenAI, we want Json object back in its response. OpenAI in its documentation recommend that it's still important that you mention in your prompt that a json response is required even if you specify format in this argument.\n",
    "        )\n",
    "        \n",
    "        # response = openai.chat.completions.create(\n",
    "        #     model=MODEL,  # Use a lightweight model for efficiency\n",
    "        #     messages=[{\"role\": \"system\", \"content\": \"You are an expert at summarizing website content.\"},\n",
    "        #               {\"role\": \"user\", \"content\": prompt}],\n",
    "        #     max_tokens=150\n",
    "        # )\n",
    "        return response.choices[0].message.content #response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Summarize each webpage\n",
    "summarized_pages = {}\n",
    "for url, content in collected_pages.items():\n",
    "    print(f\"Summarizing: {url}\")\n",
    "    summary = summarize_text(content)\n",
    "    summarized_pages[url] = summary\n",
    "\n",
    "# Save summaries for the next step\n",
    "with open(\"summarized_pages.json\", \"w\") as f:\n",
    "    json.dump(summarized_pages, f, indent=4)\n",
    "\n",
    "print(\"Summarization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f858d9df-d24c-4c50-a104-134c432c978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant pages found: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "\n",
    "# Load summarized web pages\n",
    "with open(\"collected_pages.json\", \"r\") as f:\n",
    "    summarized_pages = json.load(f)\n",
    "\n",
    "# Load job description\n",
    "# job_description = \"\"\"\n",
    "# Paste the job description here.\n",
    "# \"\"\"  # Replace with the actual job description\n",
    "\n",
    "# OpenAI API Configuration (Replace with your API key)\n",
    "# openai.api_key = \"your-api-key\"\n",
    "\n",
    "def is_relevant(summary, job_description):\n",
    "    \"\"\"Use OpenAI-mini to check if a webpage summary is relevant to the job description.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    The following is a job description:\n",
    "    {job_description}\n",
    "\n",
    "    Below is a summary of a webpage:\n",
    "    {summary}\n",
    "\n",
    "    Does this webpage contain information relevant to the job description? \n",
    "    Answer with 'yes' or 'no' and explain briefly why.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in analyzing job descriptions and company information.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        result = response.choices[0].message.content \n",
    "        return \"yes\" in result  # If OpenAI responds with \"yes\", it's relevant\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining relevance: {e}\")\n",
    "        return False\n",
    "\n",
    "# Filter relevant pages\n",
    "relevant_pages = {url: summary for url, summary in summarized_pages.items() if is_relevant(summary, job_description)}\n",
    "\n",
    "# Save relevant pages\n",
    "with open(\"relevant_pages.json\", \"w\") as f:\n",
    "    json.dump(relevant_pages, f, indent=4)\n",
    "\n",
    "print(f\"Relevant pages found: {len(relevant_pages)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b063c0a-bf82-4661-8c84-1ad2b5c1ddcd",
   "metadata": {},
   "source": [
    "# Using google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33e7872e-ec04-4afb-857e-4ad2f6c2afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating search term...\n",
      "Searching Google for: \"Zoetis Precision Animal Health generative AI internship news projects\" Zoetis\n",
      "Processing: https://www.zoetis.com/news-and-insights/blog/transforming-drug-discovery-and-development-with-generative-ai\n",
      "Processing: https://zoetis.wd5.myworkdayjobs.com/en-US/zoetis/job/Precision-Animal-Health-Generative-AI-Intern_JR00016811-1\n",
      "Processing: https://www.linkedin.com/posts/rodrigo-carranza-2a66007b_precision-animal-health-generative-ai-intern-activity-7283004798772125696-ixzV\n",
      "Processing: https://www.linkedin.com/posts/di-liang_precision-animal-health-generative-ai-intern-activity-7267203648361766914-Eu5Y\n",
      "Processing: https://www.zoetis.com/join-us/intern-at-zoetis\n",
      "Processing: https://www.ziprecruiter.com/co/zoetis/Jobs/Research-Intern\n",
      "Processing: https://www.indeed.com/cmp/Zoetis/jobs\n",
      "Processing: https://zoetis.wd5.myworkdayjobs.com/en-US/zoetis/job/Organic-Chemistry-Process-Scientist_JR00016782-1\n",
      "Processing: https://www.zoetis.com/\n",
      "Processing: https://www.bcg.com/publications/2021/transforming-the-animal-health-industry\n",
      "Processing: https://builtin.com/job/third-party-risk-management-intern/3767239\n",
      "Processing: https://www.zoetis.com/news-and-insights/innovators-for-animals\n",
      "Processing: https://onehealthdev.org/internship-opportunities-at-zoetis-inc/\n",
      "Processing: https://www.facebook.com/katielynn444/\n",
      "Processing: https://www.zoetisus.com/news-and-media/\n",
      "Processing: https://www.glassdoor.com/Jobs/Zoetis-Jobs-E680848.htm\n",
      "Processing: https://www.zippia.com/ferring-pharmaceuticals-careers-23236/jobs/internship-jobs/\n",
      "Processing: https://www.zoetis.com/products-and-science/research-development\n",
      "Processing: https://www.instagram.com/tihoneurologists/?__d=1utm_sourceig_embed\n",
      "Processing: https://www.fieracapital.com/wp-content/uploads/default/20240827/strategy-profiles-and-results-2024-06-30.pdf\n",
      "Summarization complete! Results saved to google_search_summaries.json.\n"
     ]
    }
   ],
   "source": [
    "# !pip install googlesearch-python\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search  # Free Google search library\n",
    "\n",
    "# OpenAI API Configuration (Replace with your API key)\n",
    "# OPENAI_API_KEY = \"your-openai-key\"  # Replace with your OpenAI API key\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def generate_search_term(job_description):\n",
    "    \"\"\"Use OpenAI to generate an optimized search term based on the job description.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following job description, generate the best search term to find relevant information about this role, \n",
    "    including company projects, industry focus, and related news. The search term should be concise and effective for Google search.\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Provide only the search term without explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response=openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert at creating effective Google search queries.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        # response = openai.chat.completions.create(\n",
    "        #     model=MODEL,\n",
    "        #     messages=[{\"role\": \"system\", \"content\": \"You are an expert at creating effective Google search queries.\"},\n",
    "        #               {\"role\": \"user\", \"content\": prompt}],\n",
    "        #     # max_tokens=20\n",
    "        # )\n",
    "        return response.choices[0].message.content \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating search term: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def google_search(search_query, num_results=20):\n",
    "    \"\"\"Perform a Google search and get the first `num_results` relevant links (Free method).\"\"\"\n",
    "    links = []\n",
    "    try:\n",
    "        \n",
    "        for url in search(search_query, num_results=num_results):#, stop=num_results, pause=2):\n",
    "            links.append(url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search: {e}\")\n",
    "    \n",
    "    return links\n",
    "\n",
    "def extract_page_text(url):\n",
    "    \"\"\"Extract main content from a webpage (ignoring scripts and styles).\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "\n",
    "        text = soup.get_text(separator=\" \", strip=True)\n",
    "        return text[:5000]  # Limit content to avoid excessive text\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content from {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Use OpenAI-mini to summarize a webpage's content.\"\"\"\n",
    "    prompt = f\"Summarize the following webpage content in one concise paragraph:\\n\\n{text[:4000]}\"  # Truncate if too long\n",
    "\n",
    "    try:\n",
    "        response=openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert at summarizing website content.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        # response = openai.chat.completions.create(\n",
    "        #     model=MODEL,\n",
    "        #     messages=[{\"role\": \"system\", \"content\": \"You are an expert at summarizing website content.\"},\n",
    "        #               {\"role\": \"user\", \"content\": prompt}],\n",
    "        #     # max_tokens=150\n",
    "        # )\n",
    "        return response.choices[0].message.content \n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def main(job_description, company_name):\n",
    "    \"\"\"Main function to generate a search term, search Google, extract page summaries, and store results.\"\"\"\n",
    "    print(\"Generating search term...\")\n",
    "    search_term = generate_search_term(job_description)\n",
    "    search_query = f\"{search_term} {company_name}\"  # Append company name to the search term\n",
    "\n",
    "    print(f\"Searching Google for: {search_query}\")\n",
    "    links = google_search(search_query)\n",
    "\n",
    "    summarized_pages = {}\n",
    "    \n",
    "    for url in links:\n",
    "        print(f\"Processing: {url}\")\n",
    "        page_content = extract_page_text(url)\n",
    "        \n",
    "        if page_content:\n",
    "            summary = summarize_text(page_content)\n",
    "            summarized_pages[url] = summary\n",
    "        \n",
    "        time.sleep(1)  # Delay to avoid overwhelming the servers\n",
    "\n",
    "    # Save results\n",
    "    with open(\"google_search_summaries.json\", \"w\") as f:\n",
    "        json.dump(summarized_pages, f, indent=4)\n",
    "\n",
    "    print(\"Summarization complete! Results saved to google_search_summaries.json.\")\n",
    "\n",
    "# Example Usage\n",
    "# job_description = \"\"\"\n",
    "# Paste the job description here.\n",
    "# \"\"\"  # Replace with actual job description\n",
    "company_name = \"Zoetis\"\n",
    "main(job_description, company_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee659c-9e8b-46fa-bb35-39c591e8c961",
   "metadata": {},
   "source": [
    "# Next step\n",
    "After searching for the job on google, add urls of relevant urls to the previous implementation (AGENT) and ask the Agent to use it for incorporating info to the output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
