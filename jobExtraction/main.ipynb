{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "42f4208b-2b24-43e9-94d3-480bd0ad44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "27e74b1f-b4b5-49ea-aaa6-58adbc4ff73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7f68-7fa9-43b9-9ed5-8cb96e4555d8",
   "metadata": {},
   "source": [
    "# Parsing HTML file and get relevant information from job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7fd96d41-b3ed-4409-a806-7de173d8b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A class to represent a Webpage\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped.\n",
    "    It stores:\n",
    "      - The raw HTML (self.html)\n",
    "      - The webpage title (self.title)\n",
    "      - The plain text content (self.text) with script/style/img/input tags removed\n",
    "      - The list of all links (self.links)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Store the raw HTML in a string attribute\n",
    "        self.html = response.text\n",
    "        \n",
    "        # Also store the byte content if you want both\n",
    "        self.body = response.content\n",
    "        \n",
    "        soup = BeautifulSoup(self.html, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        \n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "    def get_html(self):\n",
    "        \"\"\"\n",
    "        Return the raw HTML content of the webpage.\n",
    "        \"\"\"\n",
    "        return self.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "028f08b4-0796-4a08-8ab3-8224be05da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobSample = Website(\"https://careers.liebherr.com/job/Newport-News%2C-VA-Machine-Learning-Engineer-VA-23601/1174568301/?feedId=335501\")\n",
    "print(jobSample.links) # all links on the webpage\n",
    "print(jobSample.get_contents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3044115-6c67-47a5-9196-a480844e7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant. I have pasted below the raw HTML from a webpage that includes a job posting. Please thoroughly analyze the HTML and extract any and all relevant information about:\n",
    "\n",
    "1. The Job\n",
    "   - Job Title\n",
    "   - Overview / Summary\n",
    "   - Responsibilities / Duties\n",
    "   - Requirements / Qualifications\n",
    "   - Skills Needed\n",
    "   - Salary / Compensation / Benefits\n",
    "   - Location\n",
    "   - Employment Type (full-time, part-time, contract, etc.)\n",
    "   - How to Apply\n",
    "   - Any other job-related information you find\n",
    "   - Education Level\n",
    "\n",
    "2. The Company\n",
    "   - Company Name\n",
    "   - About the Company / Description / Mission\n",
    "   - Company Location(s)\n",
    "   - Industry / Sector\n",
    "   - products\n",
    "   - Any additional context about the company\n",
    "3- apply link\n",
    "If the job details or company info appear in multiple sections (such as headings like \"Responsibilities,\" \"Requirements,\" \"About Us,\" or in JSON-LD data), please gather them into one structured summary. Remove any duplicated or boilerplate text so the final result is clean. If something is missing, note that it's not found in the HTML.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_prompt += \"You should respond in JSON as mentioned below:\"\n",
    "\n",
    "\n",
    "system_prompt += \"\"\"\n",
    "two examples are: \n",
    "{\n",
    "  \"job\": [\n",
    "    {\n",
    "      \"job_Title\": \"Software Engineer\",\n",
    "      \"job_page\": \"https://example.com/jobs/software-engineer\",\n",
    "      \"posted_date\": \"2025-03-08\",\n",
    "      \"deadline\": \"IDK\",\n",
    "      \"apply_link\": \"https://example.com/jobs/software-engineer/apply\",\n",
    "      \"overview\": \"We are looking for a skilled software engineer to develop and maintain cutting-edge applications.\",\n",
    "      \"responsibilities\": \"Design scalable systems, collaborate with cross-functional teams, and implement new features based on customer feedback.\",\n",
    "      \"skills Needed\": \"Proficiency in Python, familiarity with cloud platforms (AWS or GCP), solid understanding of CI/CD practices.\",\n",
    "      \"Salay\": \"$100,000 - $120,000 per year, plus benefits\",\n",
    "      \"location\": \"New York, NY (Hybrid)\",\n",
    "      \"Employment_type\": \"Full-Time\",\n",
    "      \"how_Apply\": \"Complete the application form at the provided link or email your CV to hr@example.com.\",\n",
    "      \"Others\": \"You must be authorized to work in the US; relocation assistance is available.\",\n",
    "      \"Education\": \"Bachelor's degree in Computer Science or higher\",\n",
    "      \"company_name\": \"ExampleTech Inc.\",\n",
    "      \"About_company\": \"ExampleTech Inc. is a growing technology firm specializing in AI-driven solutions and modern software products.\",\n",
    "      \"company_locations\": \"Headquartered in New York with additional offices in San Francisco and London\",\n",
    "      \"Industry_sector\": \"Technology\",\n",
    "      \"known_for\": \"ExampleTech is known for its innovative AI research and developer-friendly culture, emphasizing continuous learning and cutting-edge projects.\",\n",
    "      \"additional_context\": \"Applicants should be comfortable with agile development methodologies and frequent code reviews.\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"careers page\",\n",
    "      \"url\": \"https://example.com/careers\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "example2:\n",
    "{\n",
    "  \"job\": [\n",
    "    {\n",
    "      \"job_Title\": \"Digital Marketing Manager\",\n",
    "      \"job_page\": \"https://anotherexample.org/careers/digital-marketing-manager\",\n",
    "      \"posted_date\": \"IDK\",\n",
    "      \"deadline\": \"2025-10-01\",\n",
    "      \"apply_link\": \"https://anotherexample.org/careers/apply/digital-marketing-manager\",\n",
    "      \"overview\": \"Seeking an experienced Digital Marketing Manager to drive online campaigns and brand awareness.\",\n",
    "      \"responsibilities\": \"Develop multi-channel marketing strategies, analyze campaign performance, manage social media presence, and coordinate with design teams.\",\n",
    "      \"skills Needed\": \"SEO, SEM, data analytics, email marketing tools, content strategy, and strong communication skills.\",\n",
    "      \"Salay\": \"$70,000 - $90,000 per year plus performance bonuses\",\n",
    "      \"location\": \"Remote (US-based)\",\n",
    "      \"Employment_type\": \"Full-Time\",\n",
    "      \"how_Apply\": \"Submit your resume through the application link or send an email to marketing-hr@anotherexample.org.\",\n",
    "      \"Others\": \"International applicants may be considered depending on location and visa requirements.\",\n",
    "      \"Education\": \"Bachelor's degree in Marketing or higher\",\n",
    "      \"company_name\": \"Creative Spark Agency\",\n",
    "      \"About_company\": \"A boutique creative agency offering digital marketing and brand consulting services worldwide.\",\n",
    "      \"company_locations\": \"Main office in Los Angeles, additional teams in Europe and Asia\",\n",
    "      \"Industry_sector\": \"Marketing and Advertising\",\n",
    "      \"known_for\": \"Creative Spark is recognized for award-winning digital campaigns and innovative storytelling that resonates with global audiences.\",\n",
    "      \"additional_context\": \"Candidates with strong video editing or graphic design experience are highly encouraged to apply.\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"careers page\",\n",
    "      \"url\": \"https://anotherexample.org/careers\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "259e8f64-3d36-41f9-889d-66ea46a138c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(HTML, link_page):\n",
    "    usr_prompt = \"You are looking at an online job posting. \\n\"\n",
    "    usr_prompt += \"Here are the contents of its landing page in HTML format including  all informtion about the job and some about the company. use this information to extract job and company information.\\n\"\n",
    "    usr_prompt += \"The page link that shows the job posting is: \"+ link_page+\"\\n\"\n",
    "    usr_prompt += f\"TML code to parse, and find job and company related content:\\n\"\n",
    "    usr_prompt += HTML\n",
    "    \n",
    "        # {HTML}\n",
    "    usr_prompt += \"\"\"    \n",
    "        When you respond, provide:\n",
    "        - If some information can not be found in the HTML code, just use IDK\n",
    "        - A clearly Job Information that provides values for all the fields in the following format:\n",
    "        {\n",
    "        \"job\": [\n",
    "            {\"job_Title\": \"Title of job in page\", \n",
    "            \"job_page\": \"https://full.url/goes/here/about\",\n",
    "            \"posted_date\":\"When job is posted if it is available in html code. Otherwise set the value of this field/attribute to IDK\",\n",
    "            \"deadline\":\"When is the deadline if available in the html code. Otherwise set the value of this field/attribute to IDK\",\n",
    "            \"apply_link\": \"decide which of the links in html code are relevant web links to apply for job\",\n",
    "            \"overview\": \"summary of the job\",\n",
    "            \"responsibilities\": \" list of tasks or duties for the role in job description\",\n",
    "            \"skills Needed\": \" all the skills which are needed for the position\",\n",
    "            \"Salay\": \"the payment for the position that is called salary, payment, compensation and benefits\",\n",
    "            \"location\": \"where the job will be, remote or in-persion. Which state is the applicant will work?\",\n",
    "            \"Employment_type\": \"Employment is full-time, part-time, contract, internship, etc\",\n",
    "            \"how_Apply\":\"How to apply to the job. Is it through a link to external website or there is options to fill for applying on the website\",\n",
    "            \"Others\":\"other job-related information that can be use to know better.\"\n",
    "            \"Education\":\"Does the job needs bachelor (BSc, BA), Master degree (MSc), Doctorate (PhD). If it say higher use the mentioned education and higher degree acceptable\"\n",
    "            \"company_name\":\"What is the name of company\",\n",
    "            \"About_company\":\"Provide information about company based on your knowledge. If you do not know about it, just put IDK for this field\",\n",
    "            \"company_locations\":\"Check if the job position is in the same location as company or they are different. If the company has multiNational or national company with different locations, provide the company location and mention other locations if you have information about it\",\n",
    "            \"Industry_sector\":\"provide the job is about which industry or expertise domain\",\n",
    "            \"known_for\": \"provide information about what is the company known about, explain as much as you can in a paragraph\",\n",
    "            \"additional_context\":\"provide information that helps job applicant to know about it and they are not mentioned in job descriptions or other attributes here\"\n",
    "            \n",
    "            },\n",
    "        ]\n",
    "    }\"\"\"\n",
    "    return usr_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc2bfd13-1f1c-4815-9835-a04e0415e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now it's time to put all of this into a function which is going to call OpenAI.\n",
    "def main(url, system_prompt):\n",
    "    website = Website(url)\n",
    "    # completion: your task is completing this conversation\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_user_prompt(website.get_contents(),url)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"} # we tell OpenAI, we want Json object back in its response. OpenAI in its documentation recommend that it's still important that you mention in your prompt that a json response is required even if you specify format in this argument.\n",
    "    )\n",
    "    result = response.choices[0].message.content \n",
    "    # dot choices zero. So what's this about? Well, as it happens we can actually in the API request ask to have multiple variations if we want, \n",
    "    # if we wanted it to generate several possible variations of the response. And we haven't done that. So we're only going to get back one.\n",
    "    # Uh, and so those variations come back in the form of these choices. But we've only got one. So choices zero is getting us the one and the only choice of the response back.\n",
    "    return json.loads(result)  # we use json.loads to bring it back as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2075e83b-58f9-4b6d-867a-c6121990ce88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': [{'job_Title': 'Machine Learning Engineer',\n",
       "   'job_page': 'https://careers.liebherr.com/job/Newport-News%2C-VA-Machine-Learning-Engineer-VA-23601/1174568301/?feedId=335501',\n",
       "   'posted_date': 'IDK',\n",
       "   'deadline': 'IDK',\n",
       "   'apply_link': 'https://careers.liebherr.com/job/Newport-News%2C-VA-Machine-Learning-Engineer-VA-23601/1174568301/?feedId=335501',\n",
       "   'overview': 'The Machine Learning Engineer develops algorithms used to analyze and predict system/component health, machine performance, and application metrics for large mining haul trucks.',\n",
       "   'responsibilities': 'Develops real time and post processing algorithms used to analyze machine data for failure prediction of electrical and mechanical equipment; develops algorithms used to analyze machine performance, efficiency, and application metrics; creates documentation to describe algorithm design; interfaces with other teams to create specifications; evaluates alternative Machine Learning tools and models; works independently and as a team member with engineers.',\n",
       "   'skills Needed': 'Master of Science or Master of Engineering in Computer Science, Computer Engineering or similar; ability to apply linear regression, classification, random forest, neural networks; knowledge of algorithms, applied mathematical techniques, Big Data techniques; proficiency in high-level software languages (Java, C/C++) and scripting languages (MATLAB, Python, Bash); knowledge of unit testing and software validation techniques.',\n",
       "   'Salay': 'Competitive salary with a comprehensive benefits package including major medical, dental, vision insurance, 401K plan with company match, paid vacation and personal days.',\n",
       "   'location': 'Newport News, VA, United States',\n",
       "   'Employment_type': 'Full-Time',\n",
       "   'how_Apply': 'Complete the online application through the provided link.',\n",
       "   'Others': 'Travel nationally and internationally up to 20% for customer sites, supplier sites, or regional proving grounds; ability to obtain safety training and certifications.',\n",
       "   'Education': \"Master's degree in Computer Science or related field preferred or Bachelor's degree acceptable.\"}],\n",
       " 'company': {'company_name': 'Liebherr Mining Equipment Newport News Co.',\n",
       "  'About_company': 'Liebherr is a global producer of construction and mining equipment, known for quality and innovation.',\n",
       "  'company_locations': 'Newport News, VA; the company has multiple locations across the United States.',\n",
       "  'Industry_sector': 'Mining Equipment Manufacturing',\n",
       "  'known_for': 'Liebherr is known for its advanced engineering and manufacturing of construction and mining machinery, including hydraulic excavators and heavy trucks. It has a strong emphasis on technology and sustainability in its products.',\n",
       "  'additional_context': 'The company promotes equal opportunity employment and offers competitive benefits alongside a commitment to safety and environmental responsibility.'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobSample = Website(\"https://careers.liebherr.com/job/Newport-News%2C-VA-Machine-Learning-Engineer-VA-23601/1174568301/?feedId=335501\")\n",
    "main(\"https://careers.liebherr.com/job/Newport-News%2C-VA-Machine-Learning-Engineer-VA-23601/1174568301/?feedId=335501\", system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d9bbe0a-a439-49b4-816a-6fc53111298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csvfile='job_search_results.csv'\n",
    "reader = csv.DictReader(csvfile)  # Use DictReader for named columns\n",
    "for row in reader:\n",
    "    url = row.get('link')\n",
    "    if url:\n",
    "        job_details = main(url, system_prompt)\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f1695-9da1-49a9-ac5b-d1a4b729de7e",
   "metadata": {},
   "source": [
    "# Google Search based on resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e67e57b-d242-4034-b6fb-dd6977f4f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f327d6b9-2c74-48f2-852a-ec54de807753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_searchTermResume_user_prompt(resume):\n",
    "#     searchTermResume_user_prompt=\"\"\"I have a resume and need relevant job search terms. Extract job titles that match my education, skills, experience, and projects. Ensure that:\n",
    "\n",
    "# You consider all aspects of my resume, including past roles, technical skills, and industry expertise.\n",
    "# You provide both direct job title matches and alternative roles I may qualify for.\n",
    "# The job titles are commonly used in the job market and include variations.\n",
    "# Organize the results into three categories:\n",
    "\n",
    "# Primary job titles (Best matches based on my experience and skills)\n",
    "# Alternative job titles (Related roles I may qualify for)\n",
    "# Emerging roles (Newer job trends that align with my skill set)\n",
    "# Here is my resume:\\n\"\"\"\n",
    "    searchTermResume_user_prompt = \"\"\"I have a resume, and I need highly relevant job search terms that align with my education, skills, experience, and projects.\n",
    "\n",
    "Extract job titles that directly match my expertise without including irrelevant suggestions.\n",
    "Ensure the titles cover general job search terms that recruiters would commonly use.\n",
    "Organize them into:\n",
    "Primary job titles (Most relevant and directly applicable)\n",
    "Alternative job titles (Closely related roles I may qualify for)\n",
    "Emerging job titles (Trending roles based on my expertise)\n",
    "Here is my resume:\"\"\"\n",
    "    searchTermResume_user_prompt+=resume\n",
    "    searchTermResume_user_prompt += \"provide the search terms as a json format\"\n",
    "    return searchTermResume_user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64d12512-60ba-4338-8381-d45d6ed22245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_resume(pdf_path):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_file = \"/home/mory/Downloads/Mory_Gharasuie_resume25.pdf\"\n",
    "resume = extract_text_pymupdf(pdf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57329efb-d189-479f-8679-5781d8dee3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchTermResume_system_prompt = \"You are an AI assistant specialized in job searching and resume analysis. Your task is to extract relevant information from a given resume and generate effective job search queries. Focus on identifying education requirement, key job titles, skills, industries, and qualifications. Ensure that the search queries cover different variations, including synonyms, industry-specific terms, and commonly used job titles. Provide structured results categorized by job title-based searches, skill-based searches, and industry-based searches\"\n",
    "# searchTermResume_system_prompt = \"\"\"You are an AI assistant that specializes in job search optimization. Given a resume, your goal is to extract relevant job titles that align with the candidate’s education, skills, experience, and projects. You must ensure that the extracted job titles:\n",
    "\n",
    "# Cover a broad range of applicable roles, including direct matches and alternative job titles.\n",
    "# Reflect the candidate's qualifications, industry, and expertise.\n",
    "# Include commonly used variations and synonyms to maximize job search effectiveness.\n",
    "# Prioritize high-relevance job roles, ensuring they match the candidate’s background.\n",
    "# Your response should provide a structured list of job titles categorized by:\n",
    "\n",
    "# Primary job titles (direct matches based on experience and skills)\n",
    "# Alternative job titles (closely related roles the candidate may qualify for)\n",
    "# Emerging roles (roles that fit the candidate’s skillset but may not be directly stated in experience)\"\"\"\n",
    "searchTermResume_system_prompt  = \"\"\"You are an AI assistant specialized in job searching and resume analysis. Your task is to extract relevant job search terms based on a candidate’s resume by identifying key job titles that align with their education, skills, experience, and projects.\n",
    "\n",
    "To ensure high accuracy, follow these steps:\n",
    "\n",
    "Extract job-related information: Identify the core fields of expertise from the resume, including education, skills, experience, and research areas.\n",
    "Generate relevant job titles: Match job roles that directly align with the candidate’s qualifications and group them into three categories:\n",
    "Primary job titles: Most relevant and high-confidence matches based on skills and experience.\n",
    "Alternative job titles: Related roles that the candidate is also well-suited for.\n",
    "Emerging roles: New or trending positions where the candidate’s skillset may be applicable.\n",
    "Ensure generalization and relevance: Avoid overly specific or niche roles unless strongly supported by the resume. Generate job titles based on commonly used industry terms.\n",
    "Examples:\n",
    "Example 1\n",
    "Resume Summary:\n",
    "\n",
    "PhD in AI & Machine Learning\n",
    "Experience in Deep Learning, NLP, and Computer Vision\n",
    "Projects with LLMs, Semi-Supervised Learning, and Data Science\n",
    "Generated Job Titles:\n",
    "\n",
    "Primary: Machine Learning Scientist, AI Researcher, Deep Learning Engineer\n",
    "Alternative: NLP Engineer, Computer Vision Engineer, Data Scientist\n",
    "Emerging: LLM Engineer, AI Product Researcher, Generative AI Engineer\n",
    "Example 2\n",
    "Resume Summary:\n",
    "\n",
    "Master’s in Data Science\n",
    "Experience with ML, Data Engineering, and Big Data\n",
    "Projects in predictive modeling and data pipelines\n",
    "Generated Job Titles:\n",
    "\n",
    "Primary: Data Scientist, ML Engineer, Data Engineer\n",
    "Alternative: AI Engineer, Applied Scientist, Research Scientist\n",
    "Emerging: MLOps Engineer, AI/ML Product Engineer\n",
    "Use this approach to process the following resume and generate only highly relevant job search terms.\"\"\"\n",
    "searchTermResume_system_prompt += \"You should provide very general search terms that does not have focus on specific skills. It should cover a category of jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87b364ca-59f7-4974-ad9b-62aa1f5d2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now it's time to put all of this into a function which is going to call OpenAI.\n",
    "def main2(resume, system_prompt):\n",
    "    # website = Website(url)\n",
    "    # completion: your task is completing this conversation\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": searchTermResume_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_searchTermResume_user_prompt(resume)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"} # we tell OpenAI, we want Json object back in its response. OpenAI in its documentation recommend that it's still important that you mention in your prompt that a json response is required even if you specify format in this argument.\n",
    "    )\n",
    "    result = response.choices[0].message.content \n",
    "    # dot choices zero. So what's this about? Well, as it happens we can actually in the API request ask to have multiple variations if we want, \n",
    "    # if we wanted it to generate several possible variations of the response. And we haven't done that. So we're only going to get back one.\n",
    "    # Uh, and so those variations come back in the form of these choices. But we've only got one. So choices zero is getting us the one and the only choice of the response back.\n",
    "    return json.loads(result)  # we use json.loads to bring it back as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4633a23f-af63-4e83-aa65-8776fb60d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = main2(resume, searchTermResume_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "232e3958-a179-4015-987d-10bcd47b7a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: google-search-results\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install serpapi\n",
    "!pip show google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "250d7f1f-01fc-4ff3-b019-040680a86465",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3D%2522Machine%2BLearning%2BEngineer%2522%2Bjob%2BOR%2Bcareer%2BOR%2Bhiring%2BOR%2Bopening%2BOR%2B%2522job%2Bopening%2522%2BOR%2B%2522career%2Bopportunities%2522%2BAND%2B%2528site%253Alinkedin.com%2BOR%2Bsite%253Aindeed.com%2BOR%2Bsite%253Aglassdoor.com%2BOR%2Bsite%253Agoogle%2529%2BAND%2B%2528%2522PhD%2Bin%2BComputer%2BScience%2522%2529%2BUnited%2BStates%26num%3D5%26hl%3Den%26start%3D0%26safe%3Dactive&hl=en&q=EhAmAIgFGBRBAADEkHeIdrbLGKvzs74GIjDv6mUjC4vR126frUqbriGuDbWqJ9oLaRaLoIK5crVRCYVVOAT9R9AQpGAe8GrsZ4cyAXJaAUM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, titles \u001b[38;5;129;01min\u001b[39;00m job_titles\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m titles:\n\u001b[0;32m---> 59\u001b[0m         all_job_listings\u001b[38;5;241m.\u001b[39mextend(\u001b[43msearch_job_titles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 🔹 Convert results to a DataFrame\u001b[39;00m\n\u001b[1;32m     62\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_job_listings)\n",
      "Cell \u001b[0;32mIn[106], line 48\u001b[0m, in \u001b[0;36msearch_job_titles\u001b[0;34m(job_title)\u001b[0m\n\u001b[1;32m     44\u001b[0m search_query_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Fetch top 10 results for the search query\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_query_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_listings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJob Title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_title\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSnippet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo snippet available\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# `googlesearch` doesn't provide a snippet\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llms/lib/python3.11/site-packages/googlesearch/__init__.py:58\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(term, num_results, lang, proxy, advanced, sleep_interval, timeout, safe, ssl_verify, region, start_num, unique)\u001b[0m\n\u001b[1;32m     54\u001b[0m fetched_links \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m() \u001b[38;5;66;03m# to keep track of links that are already seen previously\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fetched_results \u001b[38;5;241m<\u001b[39m num_results:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43m_req\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# put in file - comment for debugging purpose\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# with open('google.html', 'w') as f:\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m#     f.write(resp.text)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Parse\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(resp\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/llms/lib/python3.11/site-packages/googlesearch/__init__.py:32\u001b[0m, in \u001b[0;36m_req\u001b[0;34m(term, results, lang, start, proxies, timeout, safe, ssl_verify, region)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_req\u001b[39m(term, results, lang, start, proxies, timeout, safe, ssl_verify, region):\n\u001b[1;32m     10\u001b[0m     resp \u001b[38;5;241m=\u001b[39m get(\n\u001b[1;32m     11\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.google.com/search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         }\n\u001b[1;32m     31\u001b[0m     )\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniforge3/envs/llms/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3D%2522Machine%2BLearning%2BEngineer%2522%2Bjob%2BOR%2Bcareer%2BOR%2Bhiring%2BOR%2Bopening%2BOR%2B%2522job%2Bopening%2522%2BOR%2B%2522career%2Bopportunities%2522%2BAND%2B%2528site%253Alinkedin.com%2BOR%2Bsite%253Aindeed.com%2BOR%2Bsite%253Aglassdoor.com%2BOR%2Bsite%253Agoogle%2529%2BAND%2B%2528%2522PhD%2Bin%2BComputer%2BScience%2522%2529%2BUnited%2BStates%26num%3D5%26hl%3Den%26start%3D0%26safe%3Dactive&hl=en&q=EhAmAIgFGBRBAADEkHeIdrbLGKvzs74GIjDv6mUjC4vR126frUqbriGuDbWqJ9oLaRaLoIK5crVRCYVVOAT9R9AQpGAe8GrsZ4cyAXJaAUM"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from googlesearch import search\n",
    "import requests\n",
    "\n",
    "# 🔹 Define job titles based on categories\n",
    "\n",
    "# 🔹 Add education-related search terms\n",
    "education_terms = [\"PhD in Computer Science\"]#, \"Master's in AI\", \"Bachelor's in Software Engineering\"]\n",
    "\n",
    "# 🔹 Combine all job titles into one search query\n",
    "# all_titles = job_titles[\"Primary job titles\"] + job_titles[\"Alternative job titles\"] + job_titles[\"Emerging job titles\"]\n",
    "# query = \" OR \".join([f'\"{title}\"' for title in all_titles]) + \" job openings\"\n",
    "\n",
    "# # 🔹 Include education in the search query\n",
    "# query += \" AND (\" + \" OR \".join([f'\"{edu}\"' for edu in education_terms]) + \")\"\n",
    "# 🔹 Combine all job titles into one search query\n",
    "all_titles = job_titles[\"Primary job titles\"] + job_titles[\"Alternative job titles\"] + job_titles[\"Emerging job titles\"]\n",
    "query = \" OR \".join([f'\"{title}\"' for title in all_titles]) + \" job OR career OR hiring OR opening OR 'job opening' OR 'career opportunities'\"\n",
    "\n",
    "# 🔹 Include education in the search query\n",
    "query += \" AND (\" + \" OR \".join([f'\"{edu}\"' for edu in education_terms]) + \")\"\n",
    "\n",
    "# 🔹 Refine the query to specific job boards/sites (e.g., LinkedIn, Indeed)\n",
    "job_sites = [\"site:linkedin.com\", \"site:indeed.com\", \"site:glassdoor.com\", \"site:google\"]\n",
    "query += \" AND (\" + \" OR \".join(job_sites) + \")\"\n",
    "\n",
    "# 🔹 Define locations to filter results\n",
    "locations = [\"United States\", \"California\", \"New York\", \"Texas\"]  # Modify locations as needed\n",
    "\n",
    "\n",
    "# 🔹 Function to perform a job search query for each title and location\n",
    "\n",
    "def duckduckgo_search(query):\n",
    "    # DuckDuckGo search URL\n",
    "    url = f\"https://duckduckgo.com/html/?q={query}\"\n",
    "    \n",
    "    # Send request to DuckDuckGo\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception if the request fails\n",
    "    \n",
    "    # Parse the HTML response with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find search results (the results are in 'a' tags with class 'result__a')\n",
    "    results = []\n",
    "    for link in soup.find_all('a', {'class': 'result__a'}):\n",
    "        title = link.get_text()\n",
    "        url = link['href']\n",
    "        results.append({'title': title, 'url': url})\n",
    "        \n",
    "    return results\n",
    "\n",
    "# 🔹 Collect job listings for all job titles\n",
    "all_job_listings = []\n",
    "\n",
    "for category, titles in job_titles.items():\n",
    "    for title in titles:\n",
    "        all_job_listings.extend(search_job_titles(title))\n",
    "\n",
    "# 🔹 Convert results to a DataFrame\n",
    "df = pd.DataFrame(all_job_listings)\n",
    "\n",
    "# 🔹 Save results to CSV\n",
    "csv_filename = \"job_search_results_individual_titles.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"✅ Job results saved to {csv_filename}\")\n",
    "\n",
    "# # 🔹 Fetch job listings from Google\n",
    "# job_listings = []\n",
    "\n",
    "# for location in locations:\n",
    "#     # Perform search using `googlesearch` for each location\n",
    "#     search_query = f\"{query} {location}\"\n",
    "    \n",
    "#     # Fetch top 10 results for the search query\n",
    "#     for result in search(search_query, num_results=10):\n",
    "#         job_listings.append({\n",
    "#             \"Title\": result,  # The result title is the URL returned by search\n",
    "#             \"Location\": location,\n",
    "#             \"Link\": result,\n",
    "#             \"Snippet\": \"No snippet available\"  # `googlesearch` doesn't provide a snippet\n",
    "#         })\n",
    "\n",
    "# # 🔹 Convert results to a DataFrame\n",
    "# df = pd.DataFrame(job_listings)\n",
    "\n",
    "# # 🔹 Save results to CSV\n",
    "# csv_filename = \"job_search_results_with_location.csv\"\n",
    "# df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# print(f\"✅ Job results saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e4bcd57-86be-40a4-bda4-3b44fb5bbdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Primary job titles': ['Machine Learning Engineer',\n",
       "  'Data Scientist',\n",
       "  'Software Engineer',\n",
       "  'AI Researcher',\n",
       "  'Computer Vision Engineer'],\n",
       " 'Alternative job titles': ['Data Analyst',\n",
       "  'Deep Learning Engineer',\n",
       "  'NLP Engineer',\n",
       "  'Full Stack Developer',\n",
       "  'Software Developer'],\n",
       " 'Emerging job titles': ['AI/ML Product Engineer',\n",
       "  'Generative AI Engineer',\n",
       "  'MLOps Engineer',\n",
       "  'Chatbot Developer',\n",
       "  'Artificial Intelligence Consultant']}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
