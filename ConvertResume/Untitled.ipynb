{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44a0f84-293e-4119-89de-92ebc2699aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263929/1793766883.py:34: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections=[ResumeSection(section_name='Contact Information', items=[ResumeItem(title='Mory Gharasuie', subtitle=None, start_date=None, end_date=None, details=['Norfolk, VA, USA', 'mmoha014@odu.edu', '+1 757 287 1602', 'https://www.linkedin.com/in/mory-gharasui-53415258/', 'https://github.com/mortezamg63'], extra=None)]), ResumeSection(section_name='Education', items=[ResumeItem(title='PhD candidate in computer science', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='present', details=['GPA: 3.84/4.0', 'Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)'], extra=None), ResumeItem(title='Master of Science in Computer Engineering', subtitle='University of NabiAkram, Tabriz, Iran', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Bachelor of Science in Computer Engineering', subtitle='University of Shamsipoor, Tehran, Iran', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Technical Skills', items=[ResumeItem(title='Languages & Databases', subtitle=None, start_date=None, end_date=None, details=['Python', 'Java', 'C++', 'ASP Webform', 'C#', 'SQL', 'MySQL', 'HTML'], extra=None), ResumeItem(title='Libraries', subtitle=None, start_date=None, end_date=None, details=['Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Scikit-learn', 'NLP toolkit', 'HuggingFace', 'Pandas', 'Matplotlib', 'Seaborn', 'LangChain', 'Dask', 'BeautifulSoup', 'Flask'], extra=None), ResumeItem(title='Development Tools', subtitle=None, start_date=None, end_date=None, details=['Anaconda', 'Jupyter Notebook', 'Google Colab', 'Visual Studio', 'Git', 'Docker', 'AWS'], extra=None), ResumeItem(title='Operating Systems', subtitle=None, start_date=None, end_date=None, details=['Windows', 'Linux', 'Mac OS X'], extra=None)]), ResumeSection(section_name='Certifications', items=[ResumeItem(title='LanGraph', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='LLM Engineering', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='AWS SageMaker', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None)]), ResumeSection(section_name='Awards and Honors', items=[ResumeItem(title='Best Teaching Assistant', subtitle=None, start_date='Spring 2025', end_date=None, details=None, extra=None)]), ResumeSection(section_name='Experience', items=[ResumeItem(title='Software Developer', subtitle='Royan Communication Company, Qom, Iran', start_date='2013', end_date='2019', details=['Developing websites for small and medium-sized enterprises.', 'Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).', 'Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.'], extra=None), ResumeItem(title='Research Assistantship', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='Present', details=['Developing applications for mobile and serverless domains by leveraging ML, DL and CV.', 'Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.', 'Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.'], extra=None), ResumeItem(title='Teaching Assistantship', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='Present', details=['Programming with C/C++ and Java (CS150, CS250, CS251)', 'Teaching Labs and recitations', 'Assignment Development', 'Grading'], extra=None), ResumeItem(title='Collaboration in Developing a ChatBot', subtitle='Medical Aid, Norfolk, USA', start_date='Summer 2024', end_date=None, details=['Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.', 'Medical data extraction with reference to papers or resource.', 'Presentation of results based on standard medical format.', 'Providing relevant questions or considerations from recent papers for better diagnosis.'], extra=None)]), ResumeSection(section_name='Projects', items=[ResumeItem(title='Data Science and Machine Learning Projects', subtitle='GitHub', start_date=None, end_date=None, details=['Created and managed a repository featuring data science and machine learning projects.', 'Data processing and preprocessing', 'Exploring data analysis (EDA)', 'Feature engineering and selection', 'Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc)', 'Data visualization and interpretation'], extra=None), ResumeItem(title='Large Language Models', subtitle='GitHub', start_date=None, end_date=None, details=['Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.', 'Learning about Generative AI and leveraging some embedding models for practical applications.'], extra=None), ResumeItem(title='Pricer (Agentic LLM)', subtitle='GitHub', start_date=None, end_date=None, details=['An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).', \"GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\", 'Fine-tuned Llama3.1-8B and achieved 46.67 average error.', 'Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.', 'Use a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.'], extra=None), ResumeItem(title='Tabular Data and Semi-Supervised Learning (SSL)', subtitle=None, start_date=None, end_date=None, details=['Research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.', 'Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.', 'Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.', 'Effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.'], extra=None), ResumeItem(title='Computer Vision Projects', subtitle=None, start_date=None, end_date=None, details=['Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training. The system detects repetitions, analyzes range of motion, duration, and velocity, and assesses fatigue by tracking variations in rest times.', 'Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models. Implemented motion tracking with Kalman filters, trajectory segmentation, background subtraction, and action recognition techniques.', 'Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC). Integrated detection and tracking into a unified framework with a graphical interface for real-time video processing.'], extra=None)]), ResumeSection(section_name='Publications', items=[ResumeItem(title='LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification', subtitle='CAIP2025', start_date=None, end_date=None, details=['Under Reviewer'], extra=None), ResumeItem(title='SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning', subtitle='PAKDD 2024', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain', subtitle='ICKG 2022', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Performance Monitoring for Exercise Movements using Mobile cameras', subtitle='BodySys 2021', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='An efficient run-based method for connected component labeling', subtitle='MVIP 2015', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Real-time dynamic hand gesture recognition using hidden Markov models', subtitle='MVIP 2013', start_date=None, end_date=None, details=['Link'], extra=None)])]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "class ResumeItem(BaseModel):\n",
    "    title: str\n",
    "    subtitle: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    details: Optional[List[str]]\n",
    "    extra: Optional[Dict[str, Any]]\n",
    "\n",
    "class ResumeSection(BaseModel):\n",
    "    section_name: str\n",
    "    items: List[ResumeItem]\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    sections: List[ResumeSection]\n",
    "\n",
    "def parse_resume_with_openai(resume_text: str) -> Optional[Resume]:\n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    # openai.api_key = openai_api_key\n",
    "    prompt = f\"\"\"\n",
    "You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n",
    "Resume Text:\n",
    "\\\"\\\"\\\"\n",
    "{resume_text}\n",
    "\\\"\\\"\\\"\n",
    "Return only the JSON.\n",
    "\"\"\"\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=4096,\n",
    "        temperature=0,\n",
    "        response_format=Resume,\n",
    "    )\n",
    "    output = response.choices[0].message.parsed\n",
    "    # json_str = response['choices'][0]['message']['content']\n",
    "    # import json\n",
    "    # try:\n",
    "    #     data = json.loads(json_str)\n",
    "    #     return Resume.parse_obj(data)  # This will create ResumeSection and ResumeItem objects\n",
    "    # except (json.JSONDecodeError, ValidationError) as e:\n",
    "    #     print(\"Parsing error:\", e)\n",
    "    #     return None\n",
    "    return output\n",
    "\n",
    "def resume_to_markdown(resume):\n",
    "    md = []\n",
    "    for section in resume.sections:\n",
    "        md.append(f\"## {section.section_name}\\n\")\n",
    "        for item in section.items:\n",
    "            # Title and subtitle\n",
    "            line = f\"**{item.title}**\"\n",
    "            if item.subtitle:\n",
    "                line += f\", *{item.subtitle}*\"\n",
    "            # Dates\n",
    "            if item.start_date or item.end_date:\n",
    "                dates = []\n",
    "                if item.start_date:\n",
    "                    dates.append(item.start_date)\n",
    "                if item.end_date:\n",
    "                    dates.append(item.end_date)\n",
    "                line += f\" ({' - '.join(dates)})\"\n",
    "            md.append(line)\n",
    "            # Details\n",
    "            if item.details:\n",
    "                for detail in item.details:\n",
    "                    md.append(f\"- {detail}\")\n",
    "            # Extra fields\n",
    "            if item.extra:\n",
    "                for k, v in item.extra.items():\n",
    "                    md.append(f\"  - **{k.capitalize()}**: {v}\")\n",
    "            md.append(\"\")  # Blank line for spacing\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "resume = extract_text_from_pdf('/home/mory/jobProject/resumeBuilder2/uploads/Mory_Gharasuie_resume.pdf')\n",
    "output = parse_resume_with_openai(resume)\n",
    "# print(resume_to_markdown(output))\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01fa4ae5-76bb-4f47-ac33-d3014a12f1ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Resume' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39mResume(sections\u001b[38;5;241m=\u001b[39m[ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhD candidate in computer science\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld Dominion University\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAug 2019\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresent\u001b[39m\u001b[38;5;124m'\u001b[39m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPA: 3.84/4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearch Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaster of Science in Computer Engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUniversity of NabiAkram\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBachelor of Science in Computer Engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUniversity of Shamsipoor\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTechnical Skills\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguages & databases\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC++\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASP Webform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC#\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMySQL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTML\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLibraries\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPyTorch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScikit-learn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLP toolkit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuggingFace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPandas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeaborn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLangChain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeautifulSoup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlask\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevelopment tools\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnaconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJupyter Notebook\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoogle Colab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVisual Studio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAWS\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating Systems\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinux\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMac OS X\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCertifications\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanGraph\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM Engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAWS SageMaker\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAwards and Honors\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Teaching Assistant\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpring 2025\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoftware Developer\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoyan Communication Company\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2013\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019\u001b[39m\u001b[38;5;124m'\u001b[39m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeveloping websites for small and medium-sized enterprises.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearch Assistantship\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld Dominion University\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAug 2019\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPresent\u001b[39m\u001b[38;5;124m'\u001b[39m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeveloping applications for mobile and serverless domains by leveraging ML, DL and CV.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearch on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeaching Assistantship\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld Dominion University\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAug 2019\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPresent\u001b[39m\u001b[38;5;124m'\u001b[39m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgramming with C/C++ and Java (CS150, CS250, CS251)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeaching Labs and recitations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssignment Development\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrading\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollaboration in Developing a ChatBot\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedical Aid\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummer 2024\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedical data extraction with reference to papers or resource.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPresentation of results based on standard medical format.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProviding relevant questions or considerations from recent papers for better diagnosis.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Science and Machine Learning Projects\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated and managed a repository featuring data science and machine learning projects.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThese projects involve working with various datasets, and machine learning algorithms from traditional to STOA.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m{}), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLarge Language Models\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvestigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning about Generative AI and leveraging some embedding models for practical applications.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPricer (Agentic LLM)\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms performance (average price difference) with RAG, improves from 80.9 to 55.57.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tuned Llama3.1-8B and achieved 46.67 average error.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeveloped an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsed a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTabular Data and Semi-Supervised Learning (SSL)\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeveloped domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntroduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputer Vision Projects\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).\u001b[39m\u001b[38;5;124m'\u001b[39m], extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]), ResumeSection(section_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPublications\u001b[39m\u001b[38;5;124m'\u001b[39m, items\u001b[38;5;241m=\u001b[39m[ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCAIP2025\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnder Reviewer\u001b[39m\u001b[38;5;124m'\u001b[39m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAKDD 2024\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m{}), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgressive Feature Upgrade in Semi-supervised Learning on Tabular Domain\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mICKG 2022\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance Monitoring for Exercise Movements using Mobile cameras\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBodySys 2021\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn efficient run-based method for connected component labeling\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMVIP 2015\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), ResumeItem(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal-time dynamic hand gesture recognition using hidden Markov models\u001b[39m\u001b[38;5;124m'\u001b[39m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMVIP 2013\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)])])\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Resume' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a=Resume(sections=[ResumeSection(section_name='Education', items=[ResumeItem(title='PhD candidate in computer science', subtitle='Old Dominion University', start_date='Aug 2019', end_date='present', details=['GPA: 3.84/4.0', 'Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)'], extra=None), ResumeItem(title='Master of Science in Computer Engineering', subtitle='University of NabiAkram', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Bachelor of Science in Computer Engineering', subtitle='University of Shamsipoor', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Technical Skills', items=[ResumeItem(title='Languages & databases', subtitle=None, start_date=None, end_date=None, details=['python', 'Java', 'C++', 'ASP Webform', 'C#', 'SQL', 'MySQL', 'HTML'], extra=None), ResumeItem(title='Libraries', subtitle=None, start_date=None, end_date=None, details=['Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Scikit-learn', 'NLP toolkit', 'HuggingFace', 'Pandas', 'Matplotlib', 'Seaborn', 'LangChain', 'Dask', 'BeautifulSoup', 'Flask'], extra=None), ResumeItem(title='Development tools', subtitle=None, start_date=None, end_date=None, details=['Anaconda', 'Jupyter Notebook', 'Google Colab', 'Visual Studio', 'Git', 'Docker', 'AWS'], extra=None), ResumeItem(title='Operating Systems', subtitle=None, start_date=None, end_date=None, details=['Windows', 'Linux', 'Mac OS X'], extra=None)]), ResumeSection(section_name='Certifications', items=[ResumeItem(title='LanGraph', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='LLM Engineering', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='AWS SageMaker', subtitle=None, start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Awards and Honors', items=[ResumeItem(title='Best Teaching Assistant', subtitle='Spring 2025', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Experience', items=[ResumeItem(title='Software Developer', subtitle='Royan Communication Company', start_date='2013', end_date='2019', details=['Developing websites for small and medium-sized enterprises.', 'Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).', 'Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.'], extra=None), ResumeItem(title='Research Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Developing applications for mobile and serverless domains by leveraging ML, DL and CV.', 'Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.', 'Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.'], extra=None), ResumeItem(title='Teaching Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Programming with C/C++ and Java (CS150, CS250, CS251)', 'Teaching Labs and recitations', 'Assignment Development', 'Grading'], extra=None), ResumeItem(title='Collaboration in Developing a ChatBot', subtitle='Medical Aid', start_date='Summer 2024', end_date=None, details=['Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.', 'Medical data extraction with reference to papers or resource.', 'Presentation of results based on standard medical format.', 'Providing relevant questions or considerations from recent papers for better diagnosis.'], extra=None)]), ResumeSection(section_name='Projects', items=[ResumeItem(title='Data Science and Machine Learning Projects', subtitle=None, start_date=None, end_date=None, details=['Created and managed a repository featuring data science and machine learning projects.', 'These projects involve working with various datasets, and machine learning algorithms from traditional to STOA.', 'The repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.'], extra={}), ResumeItem(title='Large Language Models', subtitle=None, start_date=None, end_date=None, details=['Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.', 'Learning about Generative AI and leveraging some embedding models for practical applications.', 'The repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.'], extra=None), ResumeItem(title='Pricer (Agentic LLM)', subtitle=None, start_date=None, end_date=None, details=['An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).', \"GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\", 'Fine-tuned Llama3.1-8B and achieved 46.67 average error.', 'Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.', 'Used a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.'], extra=None), ResumeItem(title='Tabular Data and Semi-Supervised Learning (SSL)', subtitle=None, start_date=None, end_date=None, details=['This research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.', 'Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.', 'Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.', 'The effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.'], extra=None), ResumeItem(title='Computer Vision Projects', subtitle=None, start_date=None, end_date=None, details=['Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.', 'Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.', 'Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).'], extra=None)]), ResumeSection(section_name='Publications', items=[ResumeItem(title='LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification', subtitle='CAIP2025', start_date='Under Reviewer', end_date=None, details=None, extra=None), ResumeItem(title='SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning', subtitle='PAKDD 2024', start_date=None, end_date=None, details=None, extra={}), ResumeItem(title='Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain', subtitle='ICKG 2022', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Performance Monitoring for Exercise Movements using Mobile cameras', subtitle='BodySys 2021', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='An efficient run-based method for connected component labeling', subtitle='MVIP 2015', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Real-time dynamic hand gesture recognition using hidden Markov models', subtitle='MVIP 2013', start_date=None, end_date=None, details=None, extra=None)])])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be26286c-8855-4ab4-b567-3e7f16def354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263929/1885356036.py:34: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Education\n",
      "\n",
      "**PhD candidate in computer science**, *Old Dominion University* (Aug 2019 - present)\n",
      "- GPA: 3.84/4.0\n",
      "- Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)\n",
      "\n",
      "**Master of Science in Computer Engineering**, *University of NabiAkram*\n",
      "\n",
      "**Bachelor of Science in Computer Engineering**, *University of Shamsipoor*\n",
      "\n",
      "## Technical Skills\n",
      "\n",
      "**Languages & databases**\n",
      "- python\n",
      "- Java\n",
      "- C++\n",
      "- ASP Webform\n",
      "- C#\n",
      "- SQL\n",
      "- MySQL\n",
      "- HTML\n",
      "\n",
      "**Libraries**\n",
      "- Tensorflow\n",
      "- Keras\n",
      "- PyTorch\n",
      "- OpenCV\n",
      "- Scikit-learn\n",
      "- NLP toolkit\n",
      "- HuggingFace\n",
      "- Pandas\n",
      "- Matplotlib\n",
      "- Seaborn\n",
      "- LangChain\n",
      "- Dask\n",
      "- BeautifulSoup\n",
      "- Flask\n",
      "\n",
      "**Development tools**\n",
      "- Anaconda\n",
      "- Jupyter Notebook\n",
      "- Google Colab\n",
      "- Visual Studio\n",
      "- Git\n",
      "- Docker\n",
      "- AWS\n",
      "\n",
      "**Operating Systems**\n",
      "- Windows\n",
      "- Linux\n",
      "- Mac OS X\n",
      "\n",
      "## Certifications\n",
      "\n",
      "**LanGraph**\n",
      "\n",
      "**LLM Engineering**\n",
      "\n",
      "**AWS SageMaker**\n",
      "\n",
      "## Awards and Honors\n",
      "\n",
      "**Best Teaching Assistant**, *Spring 2025*\n",
      "\n",
      "## Experience\n",
      "\n",
      "**Software Developer**, *Royan Communication Company* (2013 - 2019)\n",
      "- Developing websites for small and medium-sized enterprises.\n",
      "- Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).\n",
      "- Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.\n",
      "\n",
      "**Research Assistantship**, *Old Dominion University* (Aug 2019 - Present)\n",
      "- Developing applications for mobile and serverless domains by leveraging ML, DL and CV.\n",
      "- Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.\n",
      "- Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.\n",
      "\n",
      "**Teaching Assistantship**, *Old Dominion University* (Aug 2019 - Present)\n",
      "- Programming with C/C++ and Java (CS150, CS250, CS251)\n",
      "- Teaching Labs and recitations\n",
      "- Assignment Development\n",
      "- Grading\n",
      "\n",
      "**Collaboration in Developing a ChatBot**, *Medical Aid* (Summer 2024)\n",
      "- Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.\n",
      "- Medical data extraction with reference to papers or resource.\n",
      "- Presentation of results based on standard medical format.\n",
      "- Providing relevant questions or considerations from recent papers for better diagnosis.\n",
      "\n",
      "## Projects\n",
      "\n",
      "**Data Science and Machine Learning Projects**\n",
      "- Created and managed a repository featuring data science and machine learning projects.\n",
      "- These projects involve working with various datasets, and machine learning algorithms from traditional to STOA.\n",
      "- The repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.\n",
      "\n",
      "**Large Language Models**\n",
      "- Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.\n",
      "- Learning about Generative AI and leveraging some embedding models for practical applications.\n",
      "- The repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.\n",
      "\n",
      "**Pricer (Agentic LLM)**\n",
      "- An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).\n",
      "- GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\n",
      "- Fine-tuned Llama3.1-8B and achieved 46.67 average error.\n",
      "- Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.\n",
      "- Used a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.\n",
      "\n",
      "**Tabular Data and Semi-Supervised Learning (SSL)**\n",
      "- This research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.\n",
      "- Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.\n",
      "- Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.\n",
      "- The effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.\n",
      "\n",
      "**Computer Vision Projects**\n",
      "- Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.\n",
      "- Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.\n",
      "- Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).\n",
      "\n",
      "## Publications\n",
      "\n",
      "**LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification**, *CAIP2025*\n",
      "- Under Reviewer\n",
      "\n",
      "**SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning**, *PAKDD 2024*\n",
      "- Link\n",
      "\n",
      "**Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain**, *ICKG 2022*\n",
      "- Link\n",
      "\n",
      "**Performance Monitoring for Exercise Movements using Mobile cameras**, *BodySys 2021*\n",
      "- Link\n",
      "\n",
      "**An efficient run-based method for connected component labeling**, *MVIP 2015*\n",
      "- Link\n",
      "\n",
      "**Real-time dynamic hand gesture recognition using hidden Markov models**, *MVIP 2013*\n",
      "- Link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "class ResumeItem(BaseModel):\n",
    "    title: str\n",
    "    subtitle: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    details: Optional[List[str]]\n",
    "    extra: Optional[Dict[str, Any]]\n",
    "\n",
    "class ResumeSection(BaseModel):\n",
    "    section_name: str\n",
    "    items: List[ResumeItem]\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    sections: List[ResumeSection]\n",
    "\n",
    "def parse_resume_with_openai(resume_text: str) -> Optional[Resume]:\n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    # openai.api_key = openai_api_key\n",
    "    prompt = f\"\"\"\n",
    "You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n",
    "Resume Text:\n",
    "\\\"\\\"\\\"\n",
    "{resume_text}\n",
    "\\\"\\\"\\\"\n",
    "Return only the JSON.\n",
    "\"\"\"\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=4096,\n",
    "        temperature=0,\n",
    "        response_format=Resume,\n",
    "    )\n",
    "    output = response.choices[0].message.parsed\n",
    "    # json_str = response['choices'][0]['message']['content']\n",
    "    # import json\n",
    "    # try:\n",
    "    #     data = json.loads(json_str)\n",
    "    #     return Resume.parse_obj(data)  # This will create ResumeSection and ResumeItem objects\n",
    "    # except (json.JSONDecodeError, ValidationError) as e:\n",
    "    #     print(\"Parsing error:\", e)\n",
    "    #     return None\n",
    "    return output\n",
    "\n",
    "def resume_to_markdown(resume):\n",
    "    md = []\n",
    "    for section in resume.sections:\n",
    "        md.append(f\"## {section.section_name}\\n\")\n",
    "        for item in section.items:\n",
    "            # Title and subtitle\n",
    "            line = f\"**{item.title}**\"\n",
    "            if item.subtitle:\n",
    "                line += f\", *{item.subtitle}*\"\n",
    "            # Dates\n",
    "            if item.start_date or item.end_date:\n",
    "                dates = []\n",
    "                if item.start_date:\n",
    "                    dates.append(item.start_date)\n",
    "                if item.end_date:\n",
    "                    dates.append(item.end_date)\n",
    "                line += f\" ({' - '.join(dates)})\"\n",
    "            md.append(line)\n",
    "            # Details\n",
    "            if item.details:\n",
    "                for detail in item.details:\n",
    "                    md.append(f\"- {detail}\")\n",
    "            # Extra fields\n",
    "            if item.extra:\n",
    "                for k, v in item.extra.items():\n",
    "                    md.append(f\"  - **{k.capitalize()}**: {v}\")\n",
    "            md.append(\"\")  # Blank line for spacing\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "resume = extract_text_from_pdf('/home/mory/jobProject/resumeBuilder2/uploads/Mory_Gharasuie_resume.pdf')\n",
    "output = parse_resume_with_openai(resume)\n",
    "print(resume_to_markdown(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb3b31d-e58f-4586-bbad-a88f94611b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resume(sections=[ResumeSection(section_name='Education', items=[ResumeItem(title='PhD candidate in computer science', subtitle='Old Dominion University', start_date='Aug 2019', end_date='present', details=['GPA: 3.84/4.0', 'Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)'], extra=None), ResumeItem(title='Master of Science in Computer Engineering', subtitle='University of NabiAkram', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Bachelor of Science in Computer Engineering', subtitle='University of Shamsipoor', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Technical Skills', items=[ResumeItem(title='Languages & databases', subtitle=None, start_date=None, end_date=None, details=['python', 'Java', 'C++', 'ASP Webform', 'C#', 'SQL', 'MySQL', 'HTML'], extra=None), ResumeItem(title='Libraries', subtitle=None, start_date=None, end_date=None, details=['Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Scikit-learn', 'NLP toolkit', 'HuggingFace', 'Pandas', 'Matplotlib', 'Seaborn', 'LangChain', 'Dask', 'BeautifulSoup', 'Flask'], extra=None), ResumeItem(title='Development tools', subtitle=None, start_date=None, end_date=None, details=['Anaconda', 'Jupyter Notebook', 'Google Colab', 'Visual Studio', 'Git', 'Docker', 'AWS'], extra=None), ResumeItem(title='Operating Systems', subtitle=None, start_date=None, end_date=None, details=['Windows', 'Linux', 'Mac OS X'], extra=None)]), ResumeSection(section_name='Certifications', items=[ResumeItem(title='LanGraph', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='LLM Engineering', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='AWS SageMaker', subtitle=None, start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Awards and Honors', items=[ResumeItem(title='Best Teaching Assistant', subtitle='Spring 2025', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Experience', items=[ResumeItem(title='Software Developer', subtitle='Royan Communication Company', start_date='2013', end_date='2019', details=['Developing websites for small and medium-sized enterprises.', 'Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).', 'Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.'], extra=None), ResumeItem(title='Research Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Developing applications for mobile and serverless domains by leveraging ML, DL and CV.', 'Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.', 'Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.'], extra=None), ResumeItem(title='Teaching Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Programming with C/C++ and Java (CS150, CS250, CS251)', 'Teaching Labs and recitations', 'Assignment Development', 'Grading'], extra=None), ResumeItem(title='Collaboration in Developing a ChatBot', subtitle='Medical Aid', start_date='Summer 2024', end_date=None, details=['Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.', 'Medical data extraction with reference to papers or resource.', 'Presentation of results based on standard medical format.', 'Providing relevant questions or considerations from recent papers for better diagnosis.'], extra=None)]), ResumeSection(section_name='Projects', items=[ResumeItem(title='Data Science and Machine Learning Projects', subtitle=None, start_date=None, end_date=None, details=['Created and managed a repository featuring data science and machine learning projects.', 'These projects involve working with various datasets, and machine learning algorithms from traditional to STOA.', 'The repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.'], extra={}), ResumeItem(title='Large Language Models', subtitle=None, start_date=None, end_date=None, details=['Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.', 'Learning about Generative AI and leveraging some embedding models for practical applications.', 'The repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.'], extra={}), ResumeItem(title='Pricer (Agentic LLM)', subtitle=None, start_date=None, end_date=None, details=['An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).', \"GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\", 'Fine-tuned Llama3.1-8B and achieved 46.67 average error.', 'Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.', 'Used a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.'], extra={}), ResumeItem(title='Tabular Data and Semi-Supervised Learning (SSL)', subtitle=None, start_date=None, end_date=None, details=['This research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.', 'Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.', 'Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.', 'The effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.'], extra={}), ResumeItem(title='Computer Vision Projects', subtitle=None, start_date=None, end_date=None, details=['Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.', 'Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.', 'Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).'], extra={})]), ResumeSection(section_name='Publications', items=[ResumeItem(title='LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification', subtitle='CAIP2025', start_date=None, end_date=None, details=['Under Reviewer'], extra=None), ResumeItem(title='SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning', subtitle='PAKDD 2024', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain', subtitle='ICKG 2022', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Performance Monitoring for Exercise Movements using Mobile cameras', subtitle='BodySys 2021', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='An efficient run-based method for connected component labeling', subtitle='MVIP 2015', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Real-time dynamic hand gesture recognition using hidden Markov models', subtitle='MVIP 2013', start_date=None, end_date=None, details=['Link'], extra=None)])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
