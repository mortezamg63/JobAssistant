{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44a0f84-293e-4119-89de-92ebc2699aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263929/1793766883.py:34: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections=[ResumeSection(section_name='Contact Information', items=[ResumeItem(title='Mory Gharasuie', subtitle=None, start_date=None, end_date=None, details=['Norfolk, VA, USA', 'mmoha014@odu.edu', '+1 757 287 1602', 'https://www.linkedin.com/in/mory-gharasui-53415258/', 'https://github.com/mortezamg63'], extra=None)]), ResumeSection(section_name='Education', items=[ResumeItem(title='PhD candidate in computer science', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='present', details=['GPA: 3.84/4.0', 'Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)'], extra=None), ResumeItem(title='Master of Science in Computer Engineering', subtitle='University of NabiAkram, Tabriz, Iran', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Bachelor of Science in Computer Engineering', subtitle='University of Shamsipoor, Tehran, Iran', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Technical Skills', items=[ResumeItem(title='Languages & Databases', subtitle=None, start_date=None, end_date=None, details=['Python', 'Java', 'C++', 'ASP Webform', 'C#', 'SQL', 'MySQL', 'HTML'], extra=None), ResumeItem(title='Libraries', subtitle=None, start_date=None, end_date=None, details=['Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Scikit-learn', 'NLP toolkit', 'HuggingFace', 'Pandas', 'Matplotlib', 'Seaborn', 'LangChain', 'Dask', 'BeautifulSoup', 'Flask'], extra=None), ResumeItem(title='Development Tools', subtitle=None, start_date=None, end_date=None, details=['Anaconda', 'Jupyter Notebook', 'Google Colab', 'Visual Studio', 'Git', 'Docker', 'AWS'], extra=None), ResumeItem(title='Operating Systems', subtitle=None, start_date=None, end_date=None, details=['Windows', 'Linux', 'Mac OS X'], extra=None)]), ResumeSection(section_name='Certifications', items=[ResumeItem(title='LanGraph', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='LLM Engineering', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='AWS SageMaker', subtitle=None, start_date=None, end_date=None, details=['Link'], extra=None)]), ResumeSection(section_name='Awards and Honors', items=[ResumeItem(title='Best Teaching Assistant', subtitle=None, start_date='Spring 2025', end_date=None, details=None, extra=None)]), ResumeSection(section_name='Experience', items=[ResumeItem(title='Software Developer', subtitle='Royan Communication Company, Qom, Iran', start_date='2013', end_date='2019', details=['Developing websites for small and medium-sized enterprises.', 'Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).', 'Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.'], extra=None), ResumeItem(title='Research Assistantship', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='Present', details=['Developing applications for mobile and serverless domains by leveraging ML, DL and CV.', 'Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.', 'Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.'], extra=None), ResumeItem(title='Teaching Assistantship', subtitle='Old Dominion University, Norfolk, USA', start_date='Aug 2019', end_date='Present', details=['Programming with C/C++ and Java (CS150, CS250, CS251)', 'Teaching Labs and recitations', 'Assignment Development', 'Grading'], extra=None), ResumeItem(title='Collaboration in Developing a ChatBot', subtitle='Medical Aid, Norfolk, USA', start_date='Summer 2024', end_date=None, details=['Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.', 'Medical data extraction with reference to papers or resource.', 'Presentation of results based on standard medical format.', 'Providing relevant questions or considerations from recent papers for better diagnosis.'], extra=None)]), ResumeSection(section_name='Projects', items=[ResumeItem(title='Data Science and Machine Learning Projects', subtitle='GitHub', start_date=None, end_date=None, details=['Created and managed a repository featuring data science and machine learning projects.', 'Data processing and preprocessing', 'Exploring data analysis (EDA)', 'Feature engineering and selection', 'Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc)', 'Data visualization and interpretation'], extra=None), ResumeItem(title='Large Language Models', subtitle='GitHub', start_date=None, end_date=None, details=['Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.', 'Learning about Generative AI and leveraging some embedding models for practical applications.'], extra=None), ResumeItem(title='Pricer (Agentic LLM)', subtitle='GitHub', start_date=None, end_date=None, details=['An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).', \"GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\", 'Fine-tuned Llama3.1-8B and achieved 46.67 average error.', 'Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.', 'Use a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.'], extra=None), ResumeItem(title='Tabular Data and Semi-Supervised Learning (SSL)', subtitle=None, start_date=None, end_date=None, details=['Research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.', 'Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.', 'Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.', 'Effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.'], extra=None), ResumeItem(title='Computer Vision Projects', subtitle=None, start_date=None, end_date=None, details=['Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training. The system detects repetitions, analyzes range of motion, duration, and velocity, and assesses fatigue by tracking variations in rest times.', 'Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models. Implemented motion tracking with Kalman filters, trajectory segmentation, background subtraction, and action recognition techniques.', 'Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC). Integrated detection and tracking into a unified framework with a graphical interface for real-time video processing.'], extra=None)]), ResumeSection(section_name='Publications', items=[ResumeItem(title='LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification', subtitle='CAIP2025', start_date=None, end_date=None, details=['Under Reviewer'], extra=None), ResumeItem(title='SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning', subtitle='PAKDD 2024', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain', subtitle='ICKG 2022', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Performance Monitoring for Exercise Movements using Mobile cameras', subtitle='BodySys 2021', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='An efficient run-based method for connected component labeling', subtitle='MVIP 2015', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Real-time dynamic hand gesture recognition using hidden Markov models', subtitle='MVIP 2013', start_date=None, end_date=None, details=['Link'], extra=None)])]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "class ResumeItem(BaseModel):\n",
    "    title: str\n",
    "    subtitle: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    details: Optional[List[str]]\n",
    "    extra: Optional[Dict[str, Any]]\n",
    "\n",
    "class ResumeSection(BaseModel):\n",
    "    section_name: str\n",
    "    items: List[ResumeItem]\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    sections: List[ResumeSection]\n",
    "\n",
    "def parse_resume_with_openai(resume_text: str) -> Optional[Resume]:\n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    # openai.api_key = openai_api_key\n",
    "    prompt = f\"\"\"\n",
    "You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n",
    "Resume Text:\n",
    "\\\"\\\"\\\"\n",
    "{resume_text}\n",
    "\\\"\\\"\\\"\n",
    "Return only the JSON.\n",
    "\"\"\"\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=4096,\n",
    "        temperature=0,\n",
    "        response_format=Resume,\n",
    "    )\n",
    "    output = response.choices[0].message.parsed\n",
    "    # json_str = response['choices'][0]['message']['content']\n",
    "    # import json\n",
    "    # try:\n",
    "    #     data = json.loads(json_str)\n",
    "    #     return Resume.parse_obj(data)  # This will create ResumeSection and ResumeItem objects\n",
    "    # except (json.JSONDecodeError, ValidationError) as e:\n",
    "    #     print(\"Parsing error:\", e)\n",
    "    #     return None\n",
    "    return output\n",
    "\n",
    "def resume_to_markdown(resume):\n",
    "    md = []\n",
    "    for section in resume.sections:\n",
    "        md.append(f\"## {section.section_name}\\n\")\n",
    "        for item in section.items:\n",
    "            # Title and subtitle\n",
    "            line = f\"**{item.title}**\"\n",
    "            if item.subtitle:\n",
    "                line += f\", *{item.subtitle}*\"\n",
    "            # Dates\n",
    "            if item.start_date or item.end_date:\n",
    "                dates = []\n",
    "                if item.start_date:\n",
    "                    dates.append(item.start_date)\n",
    "                if item.end_date:\n",
    "                    dates.append(item.end_date)\n",
    "                line += f\" ({' - '.join(dates)})\"\n",
    "            md.append(line)\n",
    "            # Details\n",
    "            if item.details:\n",
    "                for detail in item.details:\n",
    "                    md.append(f\"- {detail}\")\n",
    "            # Extra fields\n",
    "            if item.extra:\n",
    "                for k, v in item.extra.items():\n",
    "                    md.append(f\"  - **{k.capitalize()}**: {v}\")\n",
    "            md.append(\"\")  # Blank line for spacing\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "resume = extract_text_from_pdf('/home/mory/jobProject/resumeBuilder2/uploads/Mory_Gharasuie_resume.pdf')\n",
    "output = parse_resume_with_openai(resume)\n",
    "# print(resume_to_markdown(output))\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be26286c-8855-4ab4-b567-3e7f16def354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263929/1885356036.py:34: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Education\n",
      "\n",
      "**PhD candidate in computer science**, *Old Dominion University* (Aug 2019 - present)\n",
      "- GPA: 3.84/4.0\n",
      "- Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)\n",
      "\n",
      "**Master of Science in Computer Engineering**, *University of NabiAkram*\n",
      "\n",
      "**Bachelor of Science in Computer Engineering**, *University of Shamsipoor*\n",
      "\n",
      "## Technical Skills\n",
      "\n",
      "**Languages & databases**\n",
      "- python\n",
      "- Java\n",
      "- C++\n",
      "- ASP Webform\n",
      "- C#\n",
      "- SQL\n",
      "- MySQL\n",
      "- HTML\n",
      "\n",
      "**Libraries**\n",
      "- Tensorflow\n",
      "- Keras\n",
      "- PyTorch\n",
      "- OpenCV\n",
      "- Scikit-learn\n",
      "- NLP toolkit\n",
      "- HuggingFace\n",
      "- Pandas\n",
      "- Matplotlib\n",
      "- Seaborn\n",
      "- LangChain\n",
      "- Dask\n",
      "- BeautifulSoup\n",
      "- Flask\n",
      "\n",
      "**Development tools**\n",
      "- Anaconda\n",
      "- Jupyter Notebook\n",
      "- Google Colab\n",
      "- Visual Studio\n",
      "- Git\n",
      "- Docker\n",
      "- AWS\n",
      "\n",
      "**Operating Systems**\n",
      "- Windows\n",
      "- Linux\n",
      "- Mac OS X\n",
      "\n",
      "## Certifications\n",
      "\n",
      "**LanGraph**\n",
      "\n",
      "**LLM Engineering**\n",
      "\n",
      "**AWS SageMaker**\n",
      "\n",
      "## Awards and Honors\n",
      "\n",
      "**Best Teaching Assistant**, *Spring 2025*\n",
      "\n",
      "## Experience\n",
      "\n",
      "**Software Developer**, *Royan Communication Company* (2013 - 2019)\n",
      "- Developing websites for small and medium-sized enterprises.\n",
      "- Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).\n",
      "- Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.\n",
      "\n",
      "**Research Assistantship**, *Old Dominion University* (Aug 2019 - Present)\n",
      "- Developing applications for mobile and serverless domains by leveraging ML, DL and CV.\n",
      "- Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.\n",
      "- Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.\n",
      "\n",
      "**Teaching Assistantship**, *Old Dominion University* (Aug 2019 - Present)\n",
      "- Programming with C/C++ and Java (CS150, CS250, CS251)\n",
      "- Teaching Labs and recitations\n",
      "- Assignment Development\n",
      "- Grading\n",
      "\n",
      "**Collaboration in Developing a ChatBot**, *Medical Aid* (Summer 2024)\n",
      "- Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.\n",
      "- Medical data extraction with reference to papers or resource.\n",
      "- Presentation of results based on standard medical format.\n",
      "- Providing relevant questions or considerations from recent papers for better diagnosis.\n",
      "\n",
      "## Projects\n",
      "\n",
      "**Data Science and Machine Learning Projects**\n",
      "- Created and managed a repository featuring data science and machine learning projects.\n",
      "- These projects involve working with various datasets, and machine learning algorithms from traditional to STOA.\n",
      "- The repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.\n",
      "\n",
      "**Large Language Models**\n",
      "- Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.\n",
      "- Learning about Generative AI and leveraging some embedding models for practical applications.\n",
      "- The repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.\n",
      "\n",
      "**Pricer (Agentic LLM)**\n",
      "- An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).\n",
      "- GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\n",
      "- Fine-tuned Llama3.1-8B and achieved 46.67 average error.\n",
      "- Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.\n",
      "- Used a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.\n",
      "\n",
      "**Tabular Data and Semi-Supervised Learning (SSL)**\n",
      "- This research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.\n",
      "- Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.\n",
      "- Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.\n",
      "- The effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.\n",
      "\n",
      "**Computer Vision Projects**\n",
      "- Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.\n",
      "- Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.\n",
      "- Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).\n",
      "\n",
      "## Publications\n",
      "\n",
      "**LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification**, *CAIP2025*\n",
      "- Under Reviewer\n",
      "\n",
      "**SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning**, *PAKDD 2024*\n",
      "- Link\n",
      "\n",
      "**Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain**, *ICKG 2022*\n",
      "- Link\n",
      "\n",
      "**Performance Monitoring for Exercise Movements using Mobile cameras**, *BodySys 2021*\n",
      "- Link\n",
      "\n",
      "**An efficient run-based method for connected component labeling**, *MVIP 2015*\n",
      "- Link\n",
      "\n",
      "**Real-time dynamic hand gesture recognition using hidden Markov models**, *MVIP 2013*\n",
      "- Link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "class ResumeItem(BaseModel):\n",
    "    title: str\n",
    "    subtitle: Optional[str]\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    details: Optional[List[str]]\n",
    "    extra: Optional[Dict[str, Any]]\n",
    "\n",
    "class ResumeSection(BaseModel):\n",
    "    section_name: str\n",
    "    items: List[ResumeItem]\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    sections: List[ResumeSection]\n",
    "\n",
    "def parse_resume_with_openai(resume_text: str) -> Optional[Resume]:\n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    # openai.api_key = openai_api_key\n",
    "    prompt = f\"\"\"\n",
    "You are an expert resume parser. Given this resume text, extract all information into the following JSON schema: {Resume.schema_json(indent=2)}\n",
    "Resume Text:\n",
    "\\\"\\\"\\\"\n",
    "{resume_text}\n",
    "\\\"\\\"\\\"\n",
    "Return only the JSON.\n",
    "\"\"\"\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=4096,\n",
    "        temperature=0,\n",
    "        response_format=Resume,\n",
    "    )\n",
    "    output = response.choices[0].message.parsed\n",
    "    # json_str = response['choices'][0]['message']['content']\n",
    "    # import json\n",
    "    # try:\n",
    "    #     data = json.loads(json_str)\n",
    "    #     return Resume.parse_obj(data)  # This will create ResumeSection and ResumeItem objects\n",
    "    # except (json.JSONDecodeError, ValidationError) as e:\n",
    "    #     print(\"Parsing error:\", e)\n",
    "    #     return None\n",
    "    return output\n",
    "\n",
    "def resume_to_markdown(resume):\n",
    "    md = []\n",
    "    for section in resume.sections:\n",
    "        md.append(f\"## {section.section_name}\\n\")\n",
    "        for item in section.items:\n",
    "            # Title and subtitle\n",
    "            line = f\"**{item.title}**\"\n",
    "            if item.subtitle:\n",
    "                line += f\", *{item.subtitle}*\"\n",
    "            # Dates\n",
    "            if item.start_date or item.end_date:\n",
    "                dates = []\n",
    "                if item.start_date:\n",
    "                    dates.append(item.start_date)\n",
    "                if item.end_date:\n",
    "                    dates.append(item.end_date)\n",
    "                line += f\" ({' - '.join(dates)})\"\n",
    "            md.append(line)\n",
    "            # Details\n",
    "            if item.details:\n",
    "                for detail in item.details:\n",
    "                    md.append(f\"- {detail}\")\n",
    "            # Extra fields\n",
    "            if item.extra:\n",
    "                for k, v in item.extra.items():\n",
    "                    md.append(f\"  - **{k.capitalize()}**: {v}\")\n",
    "            md.append(\"\")  # Blank line for spacing\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "resume = extract_text_from_pdf('/home/mory/jobProject/resumeBuilder2/uploads/Mory_Gharasuie_resume.pdf')\n",
    "output = parse_resume_with_openai(resume)\n",
    "print(resume_to_markdown(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb3b31d-e58f-4586-bbad-a88f94611b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resume(sections=[ResumeSection(section_name='Education', items=[ResumeItem(title='PhD candidate in computer science', subtitle='Old Dominion University', start_date='Aug 2019', end_date='present', details=['GPA: 3.84/4.0', 'Research Interests: Self-Supervised Learning and Semi-supervised Learning in Imbalanced datasets (Image, Text and Tabular Domains)'], extra=None), ResumeItem(title='Master of Science in Computer Engineering', subtitle='University of NabiAkram', start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='Bachelor of Science in Computer Engineering', subtitle='University of Shamsipoor', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Technical Skills', items=[ResumeItem(title='Languages & databases', subtitle=None, start_date=None, end_date=None, details=['python', 'Java', 'C++', 'ASP Webform', 'C#', 'SQL', 'MySQL', 'HTML'], extra=None), ResumeItem(title='Libraries', subtitle=None, start_date=None, end_date=None, details=['Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Scikit-learn', 'NLP toolkit', 'HuggingFace', 'Pandas', 'Matplotlib', 'Seaborn', 'LangChain', 'Dask', 'BeautifulSoup', 'Flask'], extra=None), ResumeItem(title='Development tools', subtitle=None, start_date=None, end_date=None, details=['Anaconda', 'Jupyter Notebook', 'Google Colab', 'Visual Studio', 'Git', 'Docker', 'AWS'], extra=None), ResumeItem(title='Operating Systems', subtitle=None, start_date=None, end_date=None, details=['Windows', 'Linux', 'Mac OS X'], extra=None)]), ResumeSection(section_name='Certifications', items=[ResumeItem(title='LanGraph', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='LLM Engineering', subtitle=None, start_date=None, end_date=None, details=None, extra=None), ResumeItem(title='AWS SageMaker', subtitle=None, start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Awards and Honors', items=[ResumeItem(title='Best Teaching Assistant', subtitle='Spring 2025', start_date=None, end_date=None, details=None, extra=None)]), ResumeSection(section_name='Experience', items=[ResumeItem(title='Software Developer', subtitle='Royan Communication Company', start_date='2013', end_date='2019', details=['Developing websites for small and medium-sized enterprises.', 'Customizing web-based administration interfaces for applications on Linux server machine (such as chat server, FreeRadius server, and Elastix).', 'Enhancing the panels with support for multiple languages and designing them to be more intuitive and user-friendly, tailored to meet the specific needs and preferences of the customers.'], extra=None), ResumeItem(title='Research Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Developing applications for mobile and serverless domains by leveraging ML, DL and CV.', 'Doing research on Improving the performance of ML and DL models on classification problems for tabular data in SSL setting.', 'Research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and tabular domains.'], extra=None), ResumeItem(title='Teaching Assistantship', subtitle='Old Dominion University', start_date='Aug 2019', end_date='Present', details=['Programming with C/C++ and Java (CS150, CS250, CS251)', 'Teaching Labs and recitations', 'Assignment Development', 'Grading'], extra=None), ResumeItem(title='Collaboration in Developing a ChatBot', subtitle='Medical Aid', start_date='Summer 2024', end_date=None, details=['Utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation.', 'Medical data extraction with reference to papers or resource.', 'Presentation of results based on standard medical format.', 'Providing relevant questions or considerations from recent papers for better diagnosis.'], extra=None)]), ResumeSection(section_name='Projects', items=[ResumeItem(title='Data Science and Machine Learning Projects', subtitle=None, start_date=None, end_date=None, details=['Created and managed a repository featuring data science and machine learning projects.', 'These projects involve working with various datasets, and machine learning algorithms from traditional to STOA.', 'The repository includes: Data processing and preprocessing, Exploring data analysis (EDA), Feature engineering and selection, Machine learning development and evaluation (DNNs, Decision-Tree based models, Regression, Recommendation models, etc), Data visualization and interpretation.'], extra={}), ResumeItem(title='Large Language Models', subtitle=None, start_date=None, end_date=None, details=['Investigate the realm of retrieval-augmented generation (RAG) systems, embedding models, prompt engineering, and fine-tuning large language models.', 'Learning about Generative AI and leveraging some embedding models for practical applications.', 'The repository showcases ongoing exploration in this exciting field and will be continually updated with new insights and findings.'], extra={}), ResumeItem(title='Pricer (Agentic LLM)', subtitle=None, start_date=None, end_date=None, details=['An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML models (Random Forest, SVM, Word2Vec).', \"GPT-4o-mini's performance (average price difference) with RAG, improves from 80.9 to 55.57.\", 'Fine-tuned Llama3.1-8B and achieved 46.67 average error.', 'Developed an agent that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving 54.62 error.', 'Used a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.'], extra={}), ResumeItem(title='Tabular Data and Semi-Supervised Learning (SSL)', subtitle=None, start_date=None, end_date=None, details=['This research addresses two major challenges in machine learning with large tabular datasets: class imbalance and the transformation of heterogeneous features, particularly non-numerical ones.', 'Developed domain-specific architectures for tabular data, including Transformer-based models designed for self-supervised and semi-supervised learning scenarios.', 'Introduced target-encoding transformations within semi-supervised frameworks, incorporating the imbalance characteristics of the data.', 'The effectiveness of these methods, which demonstrate improvements over the state-of-the-art, is documented in publications.'], extra={}), ResumeItem(title='Computer Vision Projects', subtitle=None, start_date=None, end_date=None, details=['Exercise Performance Monitoring: Developed a smartphone-based system that uses pose estimation to track movements during weight training.', 'Hand Gesture Recognition: Designed a system to recognize numbers written in mid-air using Hidden Markov Models.', 'Video Analytics System: Built an object detection and tracking pipeline for mobile edge cloud computing (MECC).'], extra={})]), ResumeSection(section_name='Publications', items=[ResumeItem(title='LTBoost: Boosting Recall Uniformity for Long-Tailed Image Classification', subtitle='CAIP2025', start_date=None, end_date=None, details=['Under Reviewer'], extra=None), ResumeItem(title='SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning', subtitle='PAKDD 2024', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain', subtitle='ICKG 2022', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Performance Monitoring for Exercise Movements using Mobile cameras', subtitle='BodySys 2021', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='An efficient run-based method for connected component labeling', subtitle='MVIP 2015', start_date=None, end_date=None, details=['Link'], extra=None), ResumeItem(title='Real-time dynamic hand gesture recognition using hidden Markov models', subtitle='MVIP 2013', start_date=None, end_date=None, details=['Link'], extra=None)])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
