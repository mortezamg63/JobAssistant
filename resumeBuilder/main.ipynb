{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, trace, function_tool, OpenAIChatCompletionsModel, input_guardrail, GuardrailFunctionOutput\n",
    "from typing import Dict\n",
    "# import sendgrid\n",
    "import os\n",
    "# from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a top-notch Career Coach and Resume Optimization Assistant.\n",
    "Input: 1) A JSON “resume” object with sections→subsections→content 2) A job description text.\n",
    "You will:\n",
    "1. Extract all required keywords, skills, tools, certifications, and experiences from the job description.\n",
    "2. Categorize them (Technical Skills, Soft Skills, Tools & Technologies, Certifications, Domain Knowledge).\n",
    "3. Compare against each resume section/subsection.\n",
    "4. Split into “existing” vs. “missing”.\n",
    "5. For each item produce:\n",
    "   • section: resume section title  \n",
    "   • subsection: resume subsection title  \n",
    "   • category  \n",
    "   • keywords (list)  \n",
    "   • suggestions (list of bullet-point rewrites)\n",
    "6. **Return only valid JSON** that exactly matches the Pydantic schema `ResumeMatchOutput`.\n",
    "\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Here is my resume JSON:\n",
    "```json\n",
    "<Paste the resumeData JSON object, i.e. {\"sections\":[{\"title\":…,\"subsections\":[…]},…]}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Here is my current resume (in plain text or PDF-extracted text):\n",
    "                    {RESUME}\n",
    "                    \n",
    "                    Here is the full job description for the position I’m targeting:\n",
    "                    {JOB_DESCRIPTION}\n",
    "                    \n",
    "                    Please extract and categorize all the required keywords and skills from the job description, identify which ones I should emphasize or add to my resume, and give me concrete bullet-point rewrites or additions to ensure I’m using the right language to win this role.\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeMatch_Agent = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=system_prompt,\n",
    "        model=\"gpt-4o-mini\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Here is my current resume (in plain text or PDF-extracted text):\n",
    "                    {RESUME}\n",
    "                    \n",
    "                    Here is the full job description for the position I’m targeting:\n",
    "                    {JOB_DESCRIPTION}\n",
    "                    \n",
    "                    Please extract and categorize all the required keywords and skills from the job description, identify which ones I should emphasize or add to my resume, and give me concrete bullet-point rewrites or additions to ensure I’m using the right language to win this role.\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"About the Job\n",
    "Samsung Research AI center, located in Mountain View, CA, is currently recruiting world-class students who can thrive in a fast-pace, cross team, results-driven environment, with focus on highly visible, challenging, and cross discipline projects. You will be part of an exciting project to build an adaptive, personalized, contextual and secure AI model and system to enable fast, accurate and safe interactions tailored to users’ needs on Samsung devices.\n",
    "Job Responsibilities\n",
    "Develop and implement novel deep learning/reinforcement learning algorithms for natural language processing (text, speech) in various applications\n",
    "Contribute to the research activities of our team\n",
    "Generate creative solutions (patents) and publish in top conferences (papers)\n",
    "Requirements\n",
    "Teamwork and communication skills\n",
    "Current Ph.D. student in CS, EE, or related field\n",
    "Experience in one or more of the following areas:\n",
    "Strong background in machine learning (supervised learning, transfer learning, one-shot or few shot learning, unsupervised learning, semi-supervised learning, weakly supervised learning, meta-learning, outlier detection, etc.)\n",
    "Expertise in LLM including model architecture, training/finetuning techniques, retrieval augmented generation (RAG), reasoning and action planning, etc.\n",
    "Experience in conversational AI technologies: natural language processing (e.g., language models, semantic parsing, natural language generation etc.), dialogue (e.g., state tracking, policy learning), and representation learning (embedding, conceptualization, etc.)\n",
    "Experience in knowledge augmented AI technologies (e.g., language prompt, knowledge graph, neuro-symbolic learning)\n",
    "Experience in agentic AI is a plus.\n",
    "Experience in multimodal AI technologies for various multimodal applications.\n",
    "Experience in on-device AI technologies such as lightweight model architecture design.\n",
    "Proficiency in a neural network library (e.g., PyTorch, TensorFlow).\n",
    "Proven track record of research/publications on machine learning and artificial intelligence field (NeurIPS, ICML, ICLR, AAAI, IJCAI, CVPR, ACL, EMNLP, NAACL, TACL, etc.)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\"Mory Gharasuie\n",
    "Norfolk, VA, USA | mmoha014@odu.edu | +1 757 287 1602\n",
    "https://www.linkedin.com/in/mory-gharasui-53415258/ | https://github.com/mortezamg63\n",
    "Education\n",
    "Old Dominion University | Norfolk, USA\n",
    " Aug 2019 – present\n",
    "PhD candidate in computer science\n",
    " GPA: 3.84/4.0\n",
    "Research Interests: Machine Learning (ML), Computer Vision (CV), Semi-supervised Learing (SSL)\n",
    "Natural Language Processing (NLP), Tabular Data\n",
    "University of NabiAkram | Tabriz, Iran\n",
    "Master of Science in Computer Engineering\n",
    "University of Shamsipoor | Tehran, Iran\n",
    "Bachelor of Science in Computer Engineering\n",
    "Technical Skills\n",
    "Languages & databases: python, Java, C++, ASP Webform, C#, SQL, MySQL, HTML\n",
    "Libraries: Tensorflow, Keras, PyTorch, OpenCV, Scikit-learn, NLP toolkit, HuggingFace, Pandas, Matplotlib,LangChain, Dask, BeautifulSoup, Flask\n",
    "Development tools: Anaconda, Jupyter Notebook, Google Colab, Visual Studio, Git, Docker, AWS\n",
    "Operating Systems: Windows, Linux, Mac OS X\n",
    "Seaborn,\n",
    "Certifications\n",
    "LanGraph: Link\n",
    "LLM Engineering: Link\n",
    "Experience\n",
    "Royan Communication Company | Qom, Iran\n",
    "Software Developer\n",
    "2013 - 2019\n",
    "• Developing websites for small and medium-sized enterprises.\n",
    "• Customizing web-based administration interfaces for applications on Linux server machine (such as chat\n",
    "server, FreeRadius server, and Elastix).\n",
    "• Enhancing the panels with support for multiple languages and designing them to be more intuitive and\n",
    "user-friendly, tailored to meet the specific needs and preferences of the customers.\n",
    "Old Dominion University | Norfolk, USA\n",
    " Aug 2019 – Present\n",
    "• Research Assistantship\n",
    "– Developing applications for mobile and serverless domains by leveraging ML, DL and CV.\n",
    "– Doing research on Improving the performance of ML and DL models on classification problems for tabular\n",
    "data in SSL setting.\n",
    "–research on mitigating the impact of bias in imbalanced data in training ML and DL models in Image and\n",
    "tabular domains.\n",
    "• Teaching Assistantship\n",
    "– Programming with C/C++ and Java (CS150, CS250, CS251)\n",
    "• Teaching Labs and recitations\n",
    "• assignment Development\n",
    "• Grading\n",
    "Medical Aid | Norfolk, USA\n",
    "• Collaboration in Developing a ChatBot utilizing Large Language Models (LLMs)\n",
    "and Retrieval-Augmented Generativon.\n",
    "• Medical data extraction with reference to papers or resource\n",
    "Summer 2024\n",
    "• Presentation of results based on standard medical format\n",
    "• Providing relevant questions or considerations from recent papers for better diagnosis\n",
    "Projects\n",
    "Data Science and Machine Learning Projects | Tensorflow, PyTorch, TorchVision, OpenCV\n",
    " GitHub\n",
    "Scikit-learn, Seaborn, Matplotlib, Pandas, Git, BeautifulSoup, AWS\n",
    "Created and managed a repository featuring data science and machine learning projects. These projects involve\n",
    "working with various datasets, addressing challenges suitable for beginner to intermediate levels in data science. The\n",
    "repository includes:\n",
    "• Data processing and preprocessing\n",
    "• Exploring data analysis (EDA)\n",
    "• Feature engineering and selection\n",
    "• Machine learning development and evaluation\n",
    "• Data visualization and interpretation\n",
    "Large Language Models | HuggingFace, Pytorch, Pandas, Dask, LangChain, PEFT, RAY, OpenAI APIs\n",
    " GitHub\n",
    "In this repository, I investigate the realm of retrieval-augmented generation (RAG) systems, embedding models,\n",
    "prompt engineering, and fine-tuning large language models. Throughout this journey, I am learning about\n",
    "Generative AI and leveraging some embedding models for practical applications. The repository showcases my\n",
    "ongoing exploration in this exciting field and will be continually updated with new insights and findings.\n",
    "Pricer (Agentic LLM)| HuggingFace, Pytorch , LangChain, Chormadb, BeautifulSoup,Scikit-learn\n",
    " GitHub\n",
    "An autonomous price estimation framework using LLMs (GPT-4o, Claude, Llama 3.1-8B) and traditional ML\n",
    "models (Random Forest, SVM, Word2Vec). GPT-4o-mini's performance (average price difference) with RAG,\n",
    "improves from 80.9 to 55.57. I fine-tuned Llama3.1-8B and achieved 46.67 average error. I developed an agent\n",
    "that creates an ensemble model combining RAG+GPT-4o-mini, fine-tuned Llama, and Random Forest, achieving\n",
    "54.62 error. I use a Gradio-based UI and integrated Pushover API for real-time deal alerts from DealNews.Com.\n",
    "SAWTAB: Tabular Data and Semi-Supervised Learning (SSL) | Pytorch, Tensorflow, Tensorboard, Scikit-learn,\n",
    "Matplotlib, Seaborn\n",
    "This research project focuses on addressing two significant challenges in machine learning with large tabular\n",
    "datasets: class imbalance and the difficulties associated with one-hot encoding for high-cardinality categorical\n",
    "features. To overcome these challenges, a target encoding method is proposed for a Semi-Supervised Learning\n",
    "(SSL) setting. The method improves target encoding by leveraging unlabeled data through pseudo-labels and\n",
    "adaptively adjusting their influence to minimize the impact of noisy pseudo-labels. Experimental results on various\n",
    "datasets, compared against multiple frameworks, demonstrate that the approach achieves superior generalization\n",
    "performance.\n",
    "Publications\n",
    "PAKDD 2024: SAWTab: Smoothed Adaptive Weighting for Tabular Data in Semi-Supervised Learning | Link\n",
    "ICKG 2022: Progressive Feature Upgrade in Semi-supervised Learning on Tabular Domain | Link\n",
    "BodySys 2021: Performance Monitoring for Exercise Movements using Mobile cameras | Link\n",
    "MVIP 2015: An efficient run-based method for connected component labeling | Link\n",
    "MVIP 2013: Real-time dynamic hand gesture recognition using hidden Markov models | Link\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Let's analyze the job description and identify the critical keywords, skills, and experience requirements for the position at Samsung Research AI. Then, we'll map them back to your resume.\\n\\n### 1. Keywords and Skills from Job Description\\n\\n#### a. **Technical Skills:**\\n- Machine Learning\\n  - Supervised Learning\\n  - Transfer Learning\\n  - One-shot/Few-shot Learning\\n  - Unsupervised Learning\\n  - Semi-supervised Learning\\n  - Weakly Supervised Learning\\n  - Meta-Learning\\n  - Outlier Detection\\n- Natural Language Processing (NLP)\\n  - Language Models\\n  - Semantic Parsing\\n  - Natural Language Generation (NLG)\\n  - Dialogue Management (State Tracking, Policy Learning)\\n  - Representation Learning (Embedding, Conceptualization)\\n- Reinforcement Learning\\n- Conversational AI Technologies\\n- Knowledge Augmented AI (Language Prompt, Knowledge Graph, Neuro-Symbolic Learning)\\n- On-device AI Technologies\\n- Deep Learning Libraries (PyTorch, TensorFlow)\\n- Retrieval-Augmented Generation (RAG)\\n\\n#### b. **Soft Skills:**\\n- Teamwork\\n- Communication Skills\\n- Creativity (solution generation, patent generation)\\n\\n#### c. **Research & Publications:**\\n- Proven track record of research/publications\\n- Conferences (NeurIPS, ICML, ICLR, AAAI, IJCAI, CVPR, ACL, EMNLP, NAACL, TACL)\\n\\n### 2. Mapping to Current Resume\\n\\n#### a. **Well Represented:**\\n- **Machine Learning:**\\n  - Topics such as SSL, Deep Learning, and applying ML/DL techniques.\\n  - Mentioned libraries: PyTorch, TensorFlow.\\n\\n- **Natural Language Processing:**\\n  - Experience with large language models (LLMs) in projects.\\n  \\n- **Research/Publications:**\\n  - Current engagement in research and several publications listed.\\n\\n#### b. **Missing or Under-Emphasized:**\\n- Specific frameworks mentioned in the job description like:\\n  - Transfer Learning, One-shot/Few-shot Learning\\n  - Weakly Supervised Learning\\n  - Knowledge Graph, Neuro-Symbolic Learning\\n  - Agentic AI and Multimodal AI Technologies\\n- Soft skills (Teamwork, Communication)\\n- Patents and creative solutions\\n- More detailed achievements in NLP, especially conversational AI.\\n\\n### 3. Concise, Prioritized Keywords/Skills to Emphasize:\\n\\n1. Transfer Learning\\n2. One-shot/Few-shot Learning\\n3. Weakly Supervised Learning\\n4. Knowledge Augmented AI\\n5. Neuro-Symbolic Learning\\n6. Agentic AI\\n7. Multimodal AI Technologies\\n8. Teamwork & Communication Skills\\n9. Patents & Creative Solutions\\n\\n### 4. Actionable Suggestions:\\n\\n#### a. **Bullet Point Rewrites/Additions:**\\n\\n1. **Add to Research Section:**\\n   ```plaintext\\n   - Conducting research on advanced machine learning techniques including transfer learning, one-shot learning, and weakly supervised learning to enhance model performance in various applications.\\n   ```\\n\\n2. **Expand on NLP and Diversity of Applications:**\\n   ```plaintext\\n   - Developing state-of-the-art NLP solutions, including semantic parsing, natural language generation, and dialogue systems that enhance user interaction in complex scenarios.\\n   ```\\n\\n3. **Highlight Creative Contributions:**\\n   ```plaintext\\n   - Initiated and developed novel approaches that led to the submission of patent applications in the realm of conversational AI and RAG systems.\\n   ```\\n\\n4. **Emphasize Teamwork and Communication:**\\n   ```plaintext\\n   - Collaborated effectively in cross-disciplinary teams to drive innovative AI solutions, ensuring clear communication of technical concepts and results to diverse audiences.\\n   ```\\n\\n5. **Address Multimodal AI:**\\n   ```plaintext\\n   - Engaging in research projects that explore multimodal AI techniques, integrating data from diverse sources to build comprehensive models that address complex real-world tasks.\\n   ```\\n\\n6. **Add Knowledge Augmented AI:**\\n   ```plaintext\\n   - Investigating knowledge-augmented AI frameworks, including knowledge graphs and neuro-symbolic learning methods, to enhance reasoning capabilities in AI systems.\\n   ```\\n\\n### Conclusion\\n\\nIn order to enhance your resume effectively, integrate the suggestions into your existing bullet points to align closely with the keywords and responsibilities outlined in the job description. This alignment not only emphasizes relevant skills and experiences but also demonstrates your proactive approach to fulfilling the role's requirements. Good luck with your application at Samsung Research AI Center!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await Runner.run(resumeMatch_Agent, user_prompt.format(RESUME=resume, JOB_DESCRIPTION=job_description))\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's analyze the job description and identify the critical keywords, skills, and experience requirements for the position at Samsung Research AI. Then, we'll map them back to your resume.\n",
      "\n",
      "### 1. Keywords and Skills from Job Description\n",
      "\n",
      "#### a. **Technical Skills:**\n",
      "- Machine Learning\n",
      "  - Supervised Learning\n",
      "  - Transfer Learning\n",
      "  - One-shot/Few-shot Learning\n",
      "  - Unsupervised Learning\n",
      "  - Semi-supervised Learning\n",
      "  - Weakly Supervised Learning\n",
      "  - Meta-Learning\n",
      "  - Outlier Detection\n",
      "- Natural Language Processing (NLP)\n",
      "  - Language Models\n",
      "  - Semantic Parsing\n",
      "  - Natural Language Generation (NLG)\n",
      "  - Dialogue Management (State Tracking, Policy Learning)\n",
      "  - Representation Learning (Embedding, Conceptualization)\n",
      "- Reinforcement Learning\n",
      "- Conversational AI Technologies\n",
      "- Knowledge Augmented AI (Language Prompt, Knowledge Graph, Neuro-Symbolic Learning)\n",
      "- On-device AI Technologies\n",
      "- Deep Learning Libraries (PyTorch, TensorFlow)\n",
      "- Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "#### b. **Soft Skills:**\n",
      "- Teamwork\n",
      "- Communication Skills\n",
      "- Creativity (solution generation, patent generation)\n",
      "\n",
      "#### c. **Research & Publications:**\n",
      "- Proven track record of research/publications\n",
      "- Conferences (NeurIPS, ICML, ICLR, AAAI, IJCAI, CVPR, ACL, EMNLP, NAACL, TACL)\n",
      "\n",
      "### 2. Mapping to Current Resume\n",
      "\n",
      "#### a. **Well Represented:**\n",
      "- **Machine Learning:**\n",
      "  - Topics such as SSL, Deep Learning, and applying ML/DL techniques.\n",
      "  - Mentioned libraries: PyTorch, TensorFlow.\n",
      "\n",
      "- **Natural Language Processing:**\n",
      "  - Experience with large language models (LLMs) in projects.\n",
      "  \n",
      "- **Research/Publications:**\n",
      "  - Current engagement in research and several publications listed.\n",
      "\n",
      "#### b. **Missing or Under-Emphasized:**\n",
      "- Specific frameworks mentioned in the job description like:\n",
      "  - Transfer Learning, One-shot/Few-shot Learning\n",
      "  - Weakly Supervised Learning\n",
      "  - Knowledge Graph, Neuro-Symbolic Learning\n",
      "  - Agentic AI and Multimodal AI Technologies\n",
      "- Soft skills (Teamwork, Communication)\n",
      "- Patents and creative solutions\n",
      "- More detailed achievements in NLP, especially conversational AI.\n",
      "\n",
      "### 3. Concise, Prioritized Keywords/Skills to Emphasize:\n",
      "\n",
      "1. Transfer Learning\n",
      "2. One-shot/Few-shot Learning\n",
      "3. Weakly Supervised Learning\n",
      "4. Knowledge Augmented AI\n",
      "5. Neuro-Symbolic Learning\n",
      "6. Agentic AI\n",
      "7. Multimodal AI Technologies\n",
      "8. Teamwork & Communication Skills\n",
      "9. Patents & Creative Solutions\n",
      "\n",
      "### 4. Actionable Suggestions:\n",
      "\n",
      "#### a. **Bullet Point Rewrites/Additions:**\n",
      "\n",
      "1. **Add to Research Section:**\n",
      "   ```plaintext\n",
      "   - Conducting research on advanced machine learning techniques including transfer learning, one-shot learning, and weakly supervised learning to enhance model performance in various applications.\n",
      "   ```\n",
      "\n",
      "2. **Expand on NLP and Diversity of Applications:**\n",
      "   ```plaintext\n",
      "   - Developing state-of-the-art NLP solutions, including semantic parsing, natural language generation, and dialogue systems that enhance user interaction in complex scenarios.\n",
      "   ```\n",
      "\n",
      "3. **Highlight Creative Contributions:**\n",
      "   ```plaintext\n",
      "   - Initiated and developed novel approaches that led to the submission of patent applications in the realm of conversational AI and RAG systems.\n",
      "   ```\n",
      "\n",
      "4. **Emphasize Teamwork and Communication:**\n",
      "   ```plaintext\n",
      "   - Collaborated effectively in cross-disciplinary teams to drive innovative AI solutions, ensuring clear communication of technical concepts and results to diverse audiences.\n",
      "   ```\n",
      "\n",
      "5. **Address Multimodal AI:**\n",
      "   ```plaintext\n",
      "   - Engaging in research projects that explore multimodal AI techniques, integrating data from diverse sources to build comprehensive models that address complex real-world tasks.\n",
      "   ```\n",
      "\n",
      "6. **Add Knowledge Augmented AI:**\n",
      "   ```plaintext\n",
      "   - Investigating knowledge-augmented AI frameworks, including knowledge graphs and neuro-symbolic learning methods, to enhance reasoning capabilities in AI systems.\n",
      "   ```\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In order to enhance your resume effectively, integrate the suggestions into your existing bullet points to align closely with the keywords and responsibilities outlined in the job description. This alignment not only emphasizes relevant skills and experiences but also demonstrates your proactive approach to fulfilling the role's requirements. Good luck with your application at Samsung Research AI Center!\n"
     ]
    }
   ],
   "source": [
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunResult' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(resumeMatch_Agent, user_prompt\u001b[38;5;241m.\u001b[39mformat(RESUME\u001b[38;5;241m=\u001b[39mresume, JOB_DESCRIPTION\u001b[38;5;241m=\u001b[39mjob_description))\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# result.final_output\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 6) Inspect or serialize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m(indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RunResult' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from agents import Agent, Runner\n",
    "\n",
    "# 1) Define your output schema\n",
    "class KeywordSuggestion(BaseModel):\n",
    "    category: str = Field(..., description=\"e.g. Technical Skills, Soft Skills, Tools & Technologies\")\n",
    "    keywords: List[str] = Field(..., description=\"List of keywords from the job description in this category\")\n",
    "    suggestions: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"Actionable bullet-point suggestions on how to weave these keywords into your resume\"\n",
    "    )\n",
    "\n",
    "class ResumeMatchOutput(BaseModel):\n",
    "    existing: List[KeywordSuggestion] = Field(\n",
    "        ..., \n",
    "        description=\"Keywords you already have in your resume and how to emphasize them\"\n",
    "    )\n",
    "    missing: List[KeywordSuggestion] = Field(\n",
    "        ..., \n",
    "        description=\"Keywords you are missing or under-emphasizing, with bullet-point rewrite suggestions\"\n",
    "    )\n",
    "\n",
    "# 2) Revised system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a world-class Career Coach and Resume Optimization Assistant.\n",
    "When given a resume and a job description, you will:\n",
    "1. Analyze the job description and extract all required keywords, skills, tools, certifications, and experience requirements.\n",
    "2. Categorize them into: Technical Skills, Soft Skills, Tools & Technologies, Certifications, Domain Knowledge, etc.\n",
    "3. Compare against the provided resume and split into two groups:\n",
    "   • existing: keywords already present (but may need stronger emphasis)\n",
    "   • missing: keywords absent or under-emphasized\n",
    "4. For each KeywordSuggestion, provide actionable suggestions **as separate bullet points**.\n",
    "5. **Output only valid JSON** conforming exactly to the Pydantic schema `ResumeMatchOutput`, with no extra fields.\n",
    "\"\"\"\n",
    "\n",
    "# 3) Revised user prompt\n",
    "user_prompt = \"\"\"\n",
    "Here is my current resume:\n",
    "{RESUME}\n",
    "\n",
    "Here is the target job description:\n",
    "{JOB_DESCRIPTION}\n",
    "\n",
    "Please extract and categorize the required keywords, identify which are existing vs. missing in my resume, and for each:\n",
    " • List the keywords,\n",
    " • Give bullet-point suggestions on how to integrate or emphasize them.\n",
    "\n",
    "Return the result as JSON matching the ResumeMatchOutput schema.\n",
    "\"\"\"\n",
    "\n",
    "# 4) Instantiate your Agent with structured output\n",
    "resumeMatch_Agent = Agent(\n",
    "    name=\"Professional Sales Agent\",\n",
    "    instructions=system_prompt,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=ResumeMatchOutput,   # ← Tell the Agent to produce a ResumeMatchOutput\n",
    ")\n",
    "\n",
    "# 5) Run the agent\n",
    "result = await Runner.run(resumeMatch_Agent, user_prompt.format(RESUME=resume, JOB_DESCRIPTION=job_description))\n",
    "# result.final_output\n",
    "\n",
    "# 6) Inspect or serialize\n",
    "# print(result.json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Already on Your Resume\n",
      "\n",
      "### Technical Skills\n",
      "\n",
      "- **Keywords**: machine learning, natural language processing, deep learning, reinforcement learning, transfer learning, semi-supervised learning, unsupervised learning, few-shot learning\n",
      "- **Suggestions:**\n",
      "  - Emphasize your experience with both supervised and unsupervised learning in your project descriptions.\n",
      "  - Highlight specific algorithms you have developed or implemented in deep learning or reinforcement learning.\n",
      "  - Mention any systems you have built that involve automated decision-making or adaptive models.\n",
      "\n",
      "### Soft Skills\n",
      "\n",
      "- **Keywords**: teamwork, communication skills\n",
      "- **Suggestions:**\n",
      "  - Include instances where you contributed to team success in collaborative projects.\n",
      "  - Mention any presentations or workshops you've facilitated to demonstrate communication abilities.\n",
      "\n",
      "### Certifications\n",
      "\n",
      "- **Keywords**: proven track record of research/publications, patents\n",
      "- **Suggestions:**\n",
      "  - List papers in top-tier conferences like NeurIPS, ICML, etc., clearly indicating your role in the research process.\n",
      "  - Highlight any patents or innovative contributions during your experience.\n",
      "\n",
      "## Need to Add or Emphasize\n",
      "\n",
      "### Technical Skills\n",
      "\n",
      "- **Keywords**: few-shot learning, meta-learning, agentic AI, on-device AI technologies, lightweight model architecture\n",
      "- **Suggestions:**\n",
      "  - Consider adding sections for your experience in few-shot learning and meta-learning techniques in relevant projects.\n",
      "  - Research any aspects of agentic AI that you might have encountered and include them in your projects or research descriptions.\n",
      "\n",
      "### Domain Knowledge\n",
      "\n",
      "- **Keywords**: RAG, knowledge graphs, semantic parsing, dialogue policy learning\n",
      "- **Suggestions:**\n",
      "  - Include any direct experience with retrieval augmented generation (RAG) or state tracking in your chatbot project.\n",
      "  - Clarify any specific technologies or methodologies you've used for semantic parsing or policy learning in your work.\n",
      "\n",
      "### Tools & Technologies\n",
      "\n",
      "- **Keywords**: model architecture, neuro-symbolic learning\n",
      "- **Suggestions:**\n",
      "  - Highlight tools you used to design model architectures if applicable to your projects.\n",
      "  - Discuss any exposure you have had to neuro-symbolic learning within your research or projects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_markdown(output: ResumeMatchOutput) -> str:\n",
    "    md_lines = []\n",
    "    for section_name in (\"existing\", \"missing\"):\n",
    "        header = \"Already on Your Resume\" if section_name==\"existing\" else \"Need to Add or Emphasize\"\n",
    "        md_lines.append(f\"## {header}\\n\")\n",
    "        for ks in getattr(output, section_name):\n",
    "            md_lines.append(f\"### {ks.category}\\n\")\n",
    "            md_lines.append(f\"- **Keywords**: {', '.join(ks.keywords)}\")\n",
    "            md_lines.append(f\"- **Suggestions:**\")\n",
    "            for bullet in ks.suggestions:\n",
    "                md_lines.append(f\"  - {bullet}\")\n",
    "            md_lines.append(\"\")  # blank line\n",
    "    return \"\\n\".join(md_lines)\n",
    "\n",
    "# usage:\n",
    "# result: ResumeMatchOutput = runner.run(user_prompt)\n",
    "md_report = to_markdown(result.final_output)\n",
    "print(md_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
